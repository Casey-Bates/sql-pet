# R Lazy Evaluation, remote execution, and SQL (11b)

> This chapter:
> 
> * Reviews lazy evaluation and discusses its interaction with remote query execution on a dbms 
> * Illustrates some of the differences between writing `dplyr` commands and SQL
> * Suggests some strategies for dividing the work between your local R session and the dbms

The following packages are used in this chapter:
```{r package list, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(DBI)
library(RPostgres)
library(dbplyr)
require(knitr)
library(bookdown)
library(sqlpetr)
```
Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. If not go back to [the previous Chapter][Build the pet-sql Docker Image]
```{r check on sql-pet}
sp_docker_start("sql-pet")
```
Connect to the database:
```{r connect to postgresql}
con <- sp_get_postgres_connection(
  user = Sys.getenv("DEFAULT_POSTGRES_USER_NAME"),
  password = Sys.getenv("DEFAULT_POSTGRES_PASSWORD"),
  dbname = "dvdrental",
  seconds_to_test = 10
)
```
## R's laziness and guardrails

In [the vignette for dbplyr](https://cran.r-project.org/web/packages/dbplyr/vignettes/dbplyr.html) Hadley Wikham explains:

> The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database on the remote server, not in R on your local machine. When working with databases, dplyr tries to be as lazy as possible:
> 
> * It never pulls data into R unless you explicitly ask for it.
> 
> * It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to > the database in one step.
> 

Why lazy.
Why guardrails.
How they interact

### Lazy loading

for packages

### Lazy Evaluation 

* https://colinfay.me/lazyeval/  - About lazy evaluation
* https://colinfay.me/tidyeval-1/  - Down the rabbit hole with tidy eval â€” Part 1

### Remote execution and retrieval


## Resources

Remember that in R:

* Everything that happens is a functions
* Everything that exists is an object

* http://adv-r.had.co.nz/Functions.html#function-arguments 
* http://adv-r.had.co.nz/Computing-on-the-language.html#subset


## Illustrating the interactions between lazy evaluation and remote execution

As introduced in the previous chapter, the `dplyr::tbl` function creates  an object that might **look** like a data frame, but is actually a **list** object that `dplyr` uses for constructing queries and retrieving data from the DBMS.  

```{r}
rental_table <- dplyr::tbl(con, "rental")
```


```{r}
sorted_fields <- DBI::dbListFields(con, "rental") %>% sort()
Q <- rental_table %>% select(sorted_fields)
```
> R code | Result 
> -------| --------------
> `Q %>% str` | Shows the object `Q` 
> `Q %>% show_query` | Translates the object into SQL  
> `Q %>% nrow` | Attempts to determine the number of rows 
> `Q %>% print` | Prints x rows; same as just entering `Q`  
> `Q %>% head` |  Prints the first 6 rows 
> `Q %>% collect (n = 14)` | Prints 14 rows  
> 
> 
```{r}
Q %>% str
Q %>% show_query
Q %>% nrow
Q %>% print
Q %>% head
Q %>% collect(n = 14)
```


Consider the structure of the connection object:
```{r}
str(rental_table)
```

Notice that the first list contains the source connection information.  Among other things it contains a list of variables/columns in the table:

```{r}
rental_table$ops$vars
```


### Paradigm Shift: Lazy Execution

R and `dplyr` is designed to be both lazy and smart. Lazy execution affects when a donwload happens and when processing occurs on the dbms server side.  R retrieves the full data set when explicityly told to do so via the `collect` verb, otherwise it returns only 10 rows. And `dplyr` tries to get as much work done on the server side as possible before downloading anything.  All of this is a key paradigm shift for those new to working with databases using R and `dplyr`, especially if they have been working in a straight SQL environment.

**explain why this matters here**

In the code blocks below, we demonstrate three ways to check if `dplyr` has performed lazy/delayed execution.

1.  Display the object.
2.  nrow(object)
3.  Check the pipe.

```{r Lazy Execution 1 View Output}
rental_table <- dplyr::tbl(con, "rental")
rental_table
head(rental_table, n = 25)
```
At the top of the output look for the dimensions, [?? x columns] or at the bottom for '... with more rows'

Notice that `head` should return 25 rows, but only shows the 10 rows it has can retrieve. 

```{r Lazy Execution 2 nrow of the object}
nrow(rental_table)
```

The the `rental_table` is smart enough to returns `NA` when passed to `nrow` so no execution is performed.

```{r Lazy Execution 3 summarise implies "collect"}
rental_table %>% dplyr::summarise(n = n())
rental_table %>% dplyr::summarise(n = n()) %>% show_query()
```
The `dplyr::summarise` verb does not force R to download the whole table.  It **processes** the whole table by counting all the rows on the dbms side and then downloads one number.

Next we give an example where R gets busy and returns the full data set.

```{r}
rental_table <- dplyr::tbl(con, "rental") # Lazy

collect_rental_table <- rental_table %>% collect() # Busy
collect_rental_table
```

At the top of the output, `# A tibble: 16,044 x 7` and at the bottom of the output, `# ... with 16,034 more rows` we see that `dplyr::tbl` returned all the rows associated with `collect_rental_table`.  See [Controlling number of rows returned] for additional R examples showing R getting to work, and return some or all the rows.

See more example of lazy execution can be found [Here](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html).

### Controlling the number of rows returned

The `collect` function triggers the creation of a tibble and controls the number of rows that the DBMS sends to R.  Note that in the following examples, the object dimensions are known.
```{r}
rental_table %>% collect(n = 3) %>% head()
```
In this case the `collect` function triggers the execution of a query that counts the number of records in the table by `staff_id`:
```{r}
rental_table %>%
  count(staff_id) %>%
  collect()
```

The `collect` function affects how much is downloaded, not how many rows the DBMS needs to process the query. This query processes all of the rows in the table but only displays one row of output.
```{r}
rental_table %>%
  count(staff_id) %>%
  collect(n = 1)
```
<<smy We haven't investigated this, but it looks like `dplyr` collect() function triggers a call simmilar to the dbGetQuery call above.  The default `dplyr` behavior looks like dbSendQuery() and dbFetch() model is used.>>

When you create a report to run repeatedly, you might want to put that query into R markdown.  That way you can also execute that SQL code in a chunk with the following header:

### Interactions with R Markdown


SQL and rmarkdown:
* https://bookdown.org/yihui/rmarkdown/language-engines.html#sql


  {`sql, connection=con, output.var = "query_results"`}

```{sql, connection=con, output.var = "query_results"}
SELECT "staff_id", COUNT(*) AS "n"
FROM "rental"
GROUP BY "staff_id";
```
Rmarkdown stored that query result in a tibble:
```{r}
query_results
```


## Dividing the work between R on your machine and the DBMS

They work together.

### Make the server do as much work as you can

* show_query as a first draft of SQL.  May or may not use SQL code submitted directly.

### Criteria for choosing between `dplyr` and native SQL

This probably belongs later in the book.

* performance considerations: first get the right data, then worry about performance
* Trade offs between leaving the data in PostgreSQL vs what's kept in R: 
  + browsing the data
  + larger samples and complete tables
  + using what you know to write efficient queries that do most of the work on the server

### `dplyr` tools

Where you place the `collect` function matters.
```{r}
dbDisconnect(con)
sp_docker_stop("sql-pet")
```

## DBI Package

In this chapter we touched on a number of functions from the DBI Package.  The table in file 96b shows other functions in the package.  The Chapter column references a section in the book if we have used it.

## Other resources

  * Benjamin S. Baumer, A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data: [https://arxiv.org/pdf/1708.07073](https://arxiv.org/pdf/1708.07073) 

