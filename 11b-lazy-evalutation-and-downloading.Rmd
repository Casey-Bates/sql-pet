# Lazy Evaluation and Lazy Queries (11b)

## This chapter:
> 
> * Reviews lazy evaluation and discusses its interaction with remote query execution on a dbms 
> * Demonstrates how `dplyr` queries behave in connection with several different functions
> * Suggests some strategies for dividing the work between your local R session and the dbms

### Setup

The following packages are used in this chapter:
```{r chapter package list, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(DBI)
library(RPostgres)
library(dbplyr)
require(knitr)
library(bookdown)
library(sqlpetr)
```
Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. If not go back to [the previous Chapter][Build the pet-sql Docker Image]
```{r check on sql-pet}
sp_docker_start("sql-pet")
```
Connect to the database:
```{r connect to postgresql}
con <- sp_get_postgres_connection(
  user = Sys.getenv("DEFAULT_POSTGRES_USER_NAME"),
  password = Sys.getenv("DEFAULT_POSTGRES_PASSWORD"),
  dbname = "dvdrental",
  seconds_to_test = 10
)
```

## R is lazy and comes with guardrails

By design, R is both a language and an interactive development environment (IDE).  As a language, R tries to be as efficient as possible.  As an IDE, R creates some guardrails to make it easy and safe to work with your data. For example `getOption("max.print")` prevents R from printing more rows of data than you can handle, with a nice default of `r getOption("max.print")`, which may or may not suit you.

On the other hand SQL is a *"Structured Query Language (SQL): a standard computer language for relational database management and data manipulation."* ^[https://www.techopedia.com/definition/1245/structured-query-language-sql]. SQL has has various database-specific Interactive Development Environments (IDEs): for postgreSQL it's [pgAdmin](https://www.pgadmin.org/).  Roger Peng explains in [R Programming for Data Science](https://bookdown.org/rdpeng/rprogdatascience/history-and-overview-of-r.html#basic-features-of-r) that:

> R has maintained the original S philosophy, which is that it provides a language that is both useful for interactive work, but contains a powerful programming language for developing new tools. 

This is complicated when R interacts with SQL.  In [the vignette for dbplyr](https://cran.r-project.org/web/packages/dbplyr/vignettes/dbplyr.html) Hadley Wikham explains:

> The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database on the remote server, not in R on your local machine. When working with databases, dplyr tries to be as lazy as possible:
> 
> * It never pulls data into R unless you explicitly ask for it.
> 
> * It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step.
> 

Exactly when, which and how much data is returned from the dbms is the topic of this chapter.  Exactly how the data is represented in the dbms and then translated to a data frame is discussed in the [DBI specification](https://cran.r-project.org/web/packages/DBI/vignettes/spec.html#_fetch_records_from_a_previously_executed_query_).

Eventually, if you are interacting with a dbms from R you will need to understand the differences between lazy loading, lazy evaluation, and lazy queries.

### Lazy loading

"*Lazy loading is always used for code in packages but is optional (selected by the package maintainer) for datasets in packages.*"^[https://cran.r-project.org/doc/manuals/r-release/R-ints.html#Lazy-loading]  Lazy loading means that the code for a particular function doesn't actually get loaded into memory until the last minute -- when it's actually being used.

### Lazy evaluation 

Essentially "Lazy evaluation is a programming strategy that allows a symbol to be evaluated only when needed." ^[https://colinfay.me/lazyeval/]  That means that lazy evaluation is about **symbols** such as function arguments ^[http://adv-r.had.co.nz/Functions.html#function-arguments] when they are evaluated. Tidy evaluation complicates lazy evaluation. ^[https://colinfay.me/tidyeval-1/]

### Lazy Queries

"*When you create a "lazy" query, you're creating a pointer to a set of conditions on the database, but the query isn't actually run and the data isn't actually loaded until you call "next" or some similar method to actually fetch the data and load it into an object.*" ^[https://www.quora.com/What-is-a-lazy-query]  The `collect()` function retrieves data into a local tibble.^[https://dplyr.tidyverse.org/reference/compute.html]

## Lazy evaluation and lazy queries

### Dplyr connection objects
As introduced in the previous chapter, the `dplyr::tbl` function creates  an object that might **look** like a data frame in that when you enter it on the command line, it prints a bunch of rows from the dbms table.  But is actually a **list** object that `dplyr` uses for constructing queries and retrieving data from the DBMS.  

The following code illustrates these issues.  The `dplyr::tbl` function creates the connection object that we store in an object named `rental_table`:
```{r}
rental_table <- dplyr::tbl(con, "rental")
```
At first glance, it kind of **looks** like a data frame although it only prints 10 of the table's 16,044 rows:
```{r}
rental_table
```
But consider the structure of  `rental_table`:
```{r}
str(rental_table)
```

It has two rows.  The first row contains all the information in the `con` object, which contains information about all the tables and objects in the database:
```{r}
rental_table$src$con@typnames$typname[380:437]
```
The second row contains a list of the columns in the `rental` table, among other things:

```{r}
rental_table$ops$vars
```

To illustrate the different issues involved in data retrieval, we create equivalent connection objects to link to two other tables.  
```{r}
staff_table <- dplyr::tbl(con, "staff") 
# the 'staff' table has 2 rows

customer_table <- dplyr::tbl(con, "customer") 
# the 'customer' table has 599 rows
```

## When does a lazy query trigger data retrieval?

### Create a black box query for experimentation
Here is a typical string of dplyr verbs strung together with the magrittr `%>%` command that will be used to tease out the several different behaviors that a lazy query has when passed to different R functions.  This query joins three connection objects into a query we'll call `Q`:

```{r}
Q <- rental_table %>%
  left_join(staff_table, by = c("staff_id" = "staff_id")) %>%
  rename(staff_email = email) %>%
  left_join(customer_table, by = c("customer_id" = "customer_id")) %>%
  rename(customer_email = email) %>%
  select(rental_date, staff_email, customer_email)

```

### Experiment overview
Think of `Q` as a black box for the moment.  The following examples will show how `Q` is interpreted differently by different functions. In this table, a single green check indicates that some rows are returned, two green checks indicates that all the rows are returned, and the red X indicates that no rows have are returned.

> R code | Result 
> -------| --------------
> [`Q %>% print()`](#Q %>% print\(\)) | ![](screenshots/green-check.png) Prints x rows; same as just entering `Q`  
> [`Q %>% as.tibble()`](#Q %>% as.tibble\(\)) | ![](screenshots/green-check.png)![](screenshots/green-check.png) Forces `Q` to be a tibble
> [`Q %>% head()`](#Q %>% head\(\)) | ![](screenshots/green-check.png) Prints the first 6 rows 
> [`Q %>% length()`](#Q %>% length\(\)) |  ![](screenshots/red-x.png) Counts the rows in `Q`
> [`Q %>% str()`](#Q %>% str\(x.level = 3\)) |  ![](screenshots/red-x.png)Shows the top 3 levels of the **object** `Q` 
> [`Q %>% nrow()`](#Q %>% nrow\(\)) | ![](screenshots/red-x.png) **Attempts** to determine the number of rows 
> [`Q %>% tally()`](#Q %>% tally\(\)) | ![](screenshots/green-check.png) ![](screenshots/green-check.png) Counts all the rows -- on the dbms side
> [`Q %>% collect(n = 20)`](#Q %>% collect\(\)) | ![](screenshots/green-check.png) Prints 20 rows  
> [`Q %>% collect(n = 20) %>% head()`](#Q %>% collect\(\)) | ![](screenshots/green-check.png) Prints 6 rows  
> [`Q %>% show_query()`](#Q %>% show_query\(\)) | ![](screenshots/red-x.png) **Translates** the lazy query object into SQL  
> [`Qc <- Q %>% count(customer_email, sort = TRUE)` <br /> `Qc`](#Qc <- Q %>%) | **Extends** the lazy query object
>
> 

(The next chapter will discuss how to build queries and how to explore intermediate steps.)

### Q %>% print()

Remember that `Q %>% print()` is equivalent to `print(Q)` and the same as just entering `Q` on the command line.  We use the magrittr pipe operator here because chaining functions highlights how the same object behaves differently in each use.
```{r}
Q %>% print()
```
![](screenshots/green-check.png) R retrieves 10 observations and 3 colulmns.  In its role as IDE, R has provided nicely formatted output that is similar to what it prints for a tibble, with descriptive information about the dataset and each column:

>
> \# Source:   lazy query [?? x 3] </br >
> \# Database: postgres [postgres@localhost:5432/dvdrental] </br >
>   rental_date         staff_email                  customer_email 
>   \<dttm\>              \<chr\>                        \<chr\>
>

R has not determined how many rows are left to retrieve as it notes `... with more rows`. 

### Q %>% as.tibble()

![](screenshots/green-check.png) ![](screenshots/green-check.png) In contrast to `print()`, the `as.tibble()` function causes R to download the whole table, using tibble's default of displaying only the first 10 rows.
```{r}
Q %>% as.tibble()
```

### Q %>% head()

![](screenshots/green-check.png) The `head()` function is very similar to print but has a different "`max.print`" value.
```{r}
Q %>% head()
```

### Q %>% length()

![](screenshots/red-x.png) Because the `Q` object is relatively complex, using `str()` on it prints many lines.  You can glimpse what's going on with `length()`:
```{r}
Q %>% length()
```

### Q %>% str()

![](screenshots/red-x.png) Looking inside shows some of what's going on (three levels deep):
```{r}
Q %>% str(max.level = 3) 
```

### Q %>% nrow()

![](screenshots/red-x.png) Notice the difference between `nrow()` and `tally()`. The `nrow` functions returns `NA` and does not execute a query:
```{r}
Q %>% nrow()
```

### Q %>% tally()

![](screenshots/green-check.png) The `tally` function actually counts all the rows.
```{r}
Q %>% tally()
```
The `nrow()` function knows that `Q` is a list.  On the other hand, the `tally()` function tells SQL to go count all the rows. Notice that `Q` results in 16,044 rows -- the same number of rows as `rental`.

### Q %>% collect()

![](screenshots/green-check.png) The `dplyr::collect()` function triggers a dbFetch() function behind the scenes, which forces R to download a specified number of rows:
```{r}
Q %>% collect(n = 20)
Q %>% collect(n = 20) %>% head()
```
The `collect` function triggers the creation of a tibble and controls the number of rows that the DBMS sends to R.  Notice that `head` only prints 6 of the 25 rows that R has retrieved.  

### Q %>% show_query()

```{r}
Q %>% show_query()

```
Hand-written SQL code to do the same job will probably look a lot nicer and could be more efficient, but functionally dplyr does the job.

### Qc <- Q %>% count(customer_email)

![](screenshots/red-x.png) Until `Q` is executed, we can add to it.  This behavior is the basis for a useful debugging and development process where queries are built up incrementally.
```{r}
Qc <- Q %>% count(customer_email, sort = TRUE)
```

![](screenshots/green-check.png) When all the accumulated `dplyr` verbs are executed, they are submitted to the dbms and the number of rows that are returned follow the same rules as discussed above.
```{r}
Qc
```

See more example of lazy execution can be found [Here](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html).

```{r}
dbDisconnect(con)
sp_docker_stop("sql-pet")
```


## Other resources

  * Benjamin S. Baumer, A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data: [https://arxiv.org/pdf/1708.07073](https://arxiv.org/pdf/1708.07073) 

