# Writing to the DBMS (73)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)
library(RPostgres)
library(glue)
library(knitr)
library(here)
```

```{r echo=FALSE}
read_chunk('book-src/db-login-batch-code.R')

# source(here('r-database-docker/book-src/db-login-batch-code.R'))  # use when debugging outside of knitr
```

```{r get_postgres_connection, eval=TRUE, echo=FALSE}

```
Start up the `docker-pet` container
```{r}
result <- system2("docker", "start sql-pet", stdout = TRUE, stderr = TRUE)
result


```


now connect to the database with R
```{r}

con <- wait_for_postgres(user = Sys.getenv("DEFAULT_POSTGRES_USER_NAME"),
                         password = Sys.getenv("DEFAULT_POSTGRES_PASSWORD"),
                         dbname = "dvdrental",
                         seconds_to_test = 10)
```
## create a new table

This is an example from the DBI help file
```{r}
dbWriteTable(con, "cars", head(cars, 3)) # "cars" is a built-in dataset, not to be confused with mtcars
dbReadTable(con, "cars")   # there are 3 rows

```
## Modify an existing table

```{r}
dbExecute(
  con,
  "INSERT INTO cars (speed, dist) VALUES (1, 1), (2, 2), (3, 3)"
)
dbReadTable(con, "cars")   # there are now 6 rows

# Pass values using the param argument:
dbExecute(
  con,
  "INSERT INTO cars (speed, dist) VALUES ($1, $2)",
  param = list(4:7, 5:8)
)
dbReadTable(con, "cars")   # there are now 10 rows

```

## Clean up
```{r}
dbRemoveTable(con, "cars")

# diconnect from the db
dbDisconnect(con)

result <- system2("docker", "stop sql-pet", stdout = TRUE, stderr = TRUE)
result

```

