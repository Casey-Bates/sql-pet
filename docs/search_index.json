[
["index.html", "R, Databases and Docker Chapter 1 Introduction 1.1 Using R to query a DBMS in your organization 1.2 Docker as a tool for UseRs 1.3 Docker and R on your machine 1.4 Who are we? 1.5 Prerequisites 1.6 Install Docker 1.7 Download the repo", " R, Databases and Docker Dipti Muni, Ian Frantz, John David Smith, Mary Anne Thygesen, M. Edward (Ed) Borasky, Scott Case, and Sophie Yang 2018-10-13 Chapter 1 Introduction At the end of this chapter, you will be able to Understand the importance of using R and Docker to query a DBMS and access a service like Postgres outside of R. Setup your environment to explore the use-case for useRs. 1.1 Using R to query a DBMS in your organization Large data stores in organizations are stored in databases that have specific access constraints and structural characteristics. Data documentation may be incomplete, often emphasizes operational issues rather than analytic ones, and often needs to be confirmed on the fly. Data volumes and query performance are important design constraints. R users frequently need to make sense of complex data structures and coding schemes to address incompletely formed questions so that exploratory data analysis has to be fast. Exploratory techniques for the purpose should not be reinvented (and so would benefit from more public instruction or discussion). Learning to navigate the interfaces (passwords, packages, etc.) between R and a database is difficult to simulate outside corporate walls. Resources for interface problem diagnosis behind corporate walls may or may not address all the issues that R users face, so a simulated environment is needed. 1.2 Docker as a tool for UseRs Noam Ross’s “Docker for the UseR” suggests that there are four distinct Docker use-cases for useRs. Make a fixed working environment for reproducible analysis Access a service outside of R (e.g., Postgres) Create an R based service (e.g., with plumber) Send our compute jobs to the cloud with minimal reconfiguration or revision This book explores #2 because it allows us to work on the database access issues described above and to practice on an industrial-scale DBMS. Docker is a relatively easy way to simulate the relationship between an R/RStudio session and a database – all on on a single machine, provided you have Docker installed and running. You may want to run PostgreSQL on a Docker container, avoiding any OS or system dependencies that might come up. 1.3 Docker and R on your machine Here is how R and Docker fit on your operating system in this tutorial: (This diagram needs to be updated as our directory structure evolves.) 1.4 Who are we? Dipti Muni - @deemuni Ian Franz - @ianfrantz Jim Tyhurst - @jimtyhurst John David Smith - @smithjd M. Edward (Ed) Borasky - @znmeb Maryann Tygeson @maryannet Scott Came - @scottcame Sophie Yang - @SophieMYang 1.5 Prerequisites You will need: A computer running Windows, MacOS, or Linux (Any Linux distro that will run Docker Community Edition, R and RStudio will work), R, and RStudio and Docker hosting. The database we use is PostgreSQL 10, but you do not need to install that - it’s installed via a Docker image. RStudio 1.2 is highly recommended but not required. In addition to the current version of R and RStudio, you will need the following packages: tidyverse DBI RPostgres glue dbplyr 1.6 Install Docker Install Docker. Installation depends on your operating system: On a Mac On UNIX flavors For Windows, consider these issues and follow these instructions. 1.7 Download the repo First step: download this repo. It contains source code to build a Docker container that has the dvdrental database in PostgreSQL and shows how to interact with the database from R. "],
["docker-hosting-for-windows-02.html", "Chapter 2 Docker Hosting for Windows (02) 2.1 Hardware requirements 2.2 Software requirements 2.3 Docker for Windows settings 2.4 Git, GitHub and line endings", " Chapter 2 Docker Hosting for Windows (02) At the end of this chapter, you will be able to Setup your environment for Windows. Use Git and GitHub effectively on Windows. Skip these instructions if your computer has either OSX or a Unix variant. 2.1 Hardware requirements You will need an Intel or AMD processor with 64-bit hardware and the hardware virtualization feature. Most machines you buy today will have that, but older ones may not. You will need to go into the BIOS / firmware and enable the virtualization feature. You will need at least 4 gigabytes of RAM! 2.2 Software requirements You will need Windows 7 64-bit or later. If you can afford it, I highly recommend upgrading to Windows 10 Pro. 2.2.1 Windows 7, 8, 8.1 and Windows 10 Home (64 bit) Install Docker Toolbox. The instructions are here: https://docs.docker.com/toolbox/toolbox_install_windows/. Make sure you try the test cases and they work! 2.2.2 Windows 10 Pro Install Docker for Windows stable. The instructions are here: https://docs.docker.com/docker-for-windows/install/#start-docker-for-windows. Again, make sure you try the test cases and they work. 2.3 Docker for Windows settings 2.3.1 Shared drives If you’re going to mount host files into container file systems (as we do in the following chapters), you need to set up shared drives. Open the Docker settings dialog and select Shared Drives. Check the drives you want to share. In this screenshot, the D: drive is my 1 terabyte hard drive. 2.3.2 Kubernetes Kubernetes is a container orchestration / cloud management package that’s a major DevOps tool. It’s heavily supported by Red Hat and Google, and as a result is becoming a required skill for DevOps. However, it’s overkill for this project at the moment. So you should make sure it’s not enabled. Go to the Kubernetes dialog and make sure the Enable Kubernetes checkbox is cleared. 2.4 Git, GitHub and line endings Git was originally developed for Linux - in fact, it was created by Linus Torvalds to manage hundreds of different versions of the Linux kernel on different machines all around the world. As usage has grown, Git has achieved a huge following and is the version control system used by most large open source projects, including this one. If you’re on Windows, there are some things about Git and GitHub you need to watch. First of all, there are quite a few tools for running Git on Windows, but the RStudio default and recommended one is Git for Windows (https://git-scm.com/download/win). By default, text files on Linux end with a single linefeed (\\n) character. But on Windows, text files end with a carriage return and a line feed (\\r\\n). See https://en.wikipedia.org/wiki/Newline for the gory details. Git defaults to checking files out in the native mode. So if you’re on Linux, a text file will show up with the Linux convention, and if you’re on Windows, it will show up with the Windows convention. Most of the time this doesn’t cause any problems. But Docker containers usually run Linux, and if you have files from a repository on Windows that you’ve sent to the container, the container may malfunction or give weird results. This kind of situation has caused a lot of grief for contributors to this project, so beware. In particular, executable sh or bash scripts will fail in a Docker container if they have Windows line endings. You may see an error message with \\r in it, which means the shell saw the carriage return (\\r) and gave up. But often you’ll see no hint at all what the problem was. So you need a way to tell Git that some files need to be checked out with Linux line endings. See https://help.github.com/articles/dealing-with-line-endings/ for the details. Summary: You’ll need a .gitattributes file in the root of the repository. In that file, all text files (scripts, program source, data, etc.) that are destined for a Docker container will need to have the designator &lt;spec&gt; text eol=lf, where &lt;spec&gt; is the file name specifier, for example, *.sh. This repo includes a sample: .gitattributes "],
["learning-goals-and-use-cases-03.html", "Chapter 3 Learning Goals and Use Cases (03) 3.1 Context: Why integrate R with databases using Docker? (03) 3.2 Learning Goals 3.3 Use cases 3.4 ERD Diagram", " Chapter 3 Learning Goals and Use Cases (03) At the end of this chapter, you will be able to Understand the importance of integrating R with databases using Docker. Understand the learning goals that you will have achieved by end of the tutorial. Learn the structure of the database and understand many use cases that can apply to you. 3.1 Context: Why integrate R with databases using Docker? (03) Large data stores in organizations are stored in databases that have specific access constraints and structural characteristics. Learning to navigate the gap between R and the database is difficult to simulate outside corporate walls. R users frequently need to make sense of complex data structures using diagnostic techniques that should not be reinvented (and so would benefit from more public instruction and commentary). Docker is a relatively easy way to simulate the relationship between an R/Rstudio session and database – all on on a single machine. 3.2 Learning Goals After working through this tutorial, you can expect to be able to: Run queries against PostgreSQL in an environment that simulates what you will find in a corporate setting. Understand some of the trade-offs between: queries aimed at exploration or informal investigation using dplyr; and those where performance is important because of the size of the database or the frequency with which a query is run. Rewrite dplyr queries as SQL and submit them directly. Gain some understanding of techniques for assessing query structure and performance. Set up a PostgreSQL database in a Docker environment. Understand enough about Docker to swap databases, e.g. Sports DB for the DVD rental database used in this tutorial. Or swap the database management system (DBMS), e.g. MySQL for PostgreSQL. 3.3 Use cases Imagine that you have one of several roles at our fictional company DVDs R Us and that you need to: As a data scientist, I want to know the distribution of number of rentals per month per customer, so that the Marketing department can create incentives for customers in 3 segments: Frequent Renters, Average Renters, Infrequent Renters. As the Director of Sales, I want to see the total number of rentals per month for the past 6 months and I want to know how fast our customer base is growing/shrinking per month for the past 6 months. As the Director of Marketing, I want to know which categories of DVDs are the least popular, so that I can create a campaign to draw attention to rarely used inventory. As a shipping clerk, I want to add rental information when I fulfill a shipment order. As the Director of Analytics, I want to test as much of the production R code in my shop as possible against a new release of the DBMS that the IT department is implementing next month. etc. 3.4 ERD Diagram This tutorial uses the Postgres version of “dvd rental” database, which can be downloaded here. Here’s a glimpse of it’s structure: Entity Relationship diagram for the dvdrental database "],
["docker-postgres-and-r-04.html", "Chapter 4 Docker, Postgres, and R (04) 4.1 Verify that Docker is running 4.2 Clean up if appropriate 4.3 Connect, read and write to Postgres from R 4.4 Clean up", " Chapter 4 Docker, Postgres, and R (04) At the end of this chapter, you will be able to Run, clean-up and close Docker containers. See how to keep credentials secret in code that’s visible to the world. Interact with Postgres using Rstudio inside Docker container. # Read and write to postgreSQL from R. We always load the tidyverse and some other packages, but don’t show it unless we are using packages other than tidyverse, DBI, RPostgres, and glue. 4.1 Verify that Docker is running Docker commands can be run from a terminal (e.g., the Rstudio Terminal pane) or with a system() command. In this tutorial, we use system2() so that all the output that is created externally is shown. Note that system2 calls are divided into several parts: The program that you are sending a command to. The parameters or commands that are being sent. stdout = TRUE, stderr = TRUE are two parameters that are standard in this book, so that the command’s full output is shown in the book. Check that docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;6fd0fbdcf9f6 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; 27 minutes ago Up 26 minutes 0.0.0.0:5432-&gt;5432/tcp sql-pet&quot; 4.2 Clean up if appropriate Remove the cattle and sql-pet containers if they exists (e.g., from a prior experiments). sp_docker_remove_container(&quot;cattle&quot;) ## Warning in system2(&quot;docker&quot;, docker_command, stdout = TRUE, stderr = TRUE): ## running command &#39;&#39;docker&#39; rm cattle 2&gt;&amp;1&#39; had status 1 ## [1] &quot;Error: No such container: cattle&quot; ## attr(,&quot;status&quot;) ## [1] 1 sp_docker_remove_container(&quot;sql-pet&quot;) ## Warning in system2(&quot;docker&quot;, docker_command, stdout = TRUE, stderr = TRUE): ## running command &#39;&#39;docker&#39; rm sql-pet 2&gt;&amp;1&#39; had status 1 ## [1] &quot;Error response from daemon: You cannot remove a running container 6fd0fbdcf9f67d0b2bbf47a167b29f3624a643b4ba7cc89b1b1c09e5e5a9f4c0. Stop the container before attempting removal or force remove&quot; ## attr(,&quot;status&quot;) ## [1] 1 The convention we use in this book is to assemble a command with glue so that the you can see all of its separate parts. The following chunk just constructs the command, but does not execute it. If you have problems executing a command, you can always copy the command and execute in your terminal session. docker_cmd &lt;- glue( &quot;run &quot;, # Run is the Docker command. Everything that follows are `docker run` parameters. &quot;--detach &quot;, # (or `-d`) tells Docker to disconnect from the terminal / program issuing the command &quot;--name cattle &quot;, # tells Docker to give the container a name: `cattle` &quot;--publish 5432:5432 &quot;, # tells Docker to expose the Postgres port 5432 to the local network with 5432 &quot; postgres:10 &quot; # tells Docker the image that is to be run (after downloading if necessary) ) # We name containers `cattle` for &quot;throw-aways&quot; and `pet` for ones we treasure and keep around. :-) Show and then submit the command constructed above: cat(glue(&quot; docker &quot;, docker_cmd)) ## docker run --detach --name cattle --publish 5432:5432 postgres:10 # this is how R submits it to Docker: system2(&quot;docker&quot;, docker_cmd, stdout = TRUE, stderr = TRUE) ## Warning in system2(&quot;docker&quot;, docker_cmd, stdout = TRUE, stderr = TRUE): ## running command &#39;&#39;docker&#39; run --detach --name cattle --publish 5432:5432 ## postgres:10 2&gt;&amp;1&#39; had status 125 ## [1] &quot;e9dd3830025bb4f9b253fddb12c8e2a6ec8d899584fb2afcc36d32211f517152&quot; ## [2] &quot;docker: Error response from daemon: driver failed programming external connectivity on endpoint cattle (b2ac2eea52801f889e04cdf19e52f5427d8850cd1294ebef9dac1d6f0387d665): Bind for 0.0.0.0:5432 failed: port is already allocated.&quot; ## attr(,&quot;status&quot;) ## [1] 125 Docker returns a long string of numbers. If you are running this command for the first time, Docker downloads the PostgreSQL image, which takes a bit of time. The following command shows that a container named cattle is running postgres:10. postgres is waiting for a connection: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;6fd0fbdcf9f6 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; 27 minutes ago Up 26 minutes 0.0.0.0:5432-&gt;5432/tcp sql-pet&quot; 4.3 Connect, read and write to Postgres from R 4.3.1 Pause for some security considerations We use the following sp_get_postgres_connection function, which will repeatedly try to connect to PostgreSQL. PostgreSQL can take different amounts of time to come up and be ready to accept connections from R, depending on various factors that will be discussed later on. When we call sp_get_postgres_connection we'll use environment variables that R obtains from reading a file named .Renviron. That file is not uploaded to Github and R looks for it in your default directory. To see whether you have already created that file, execute this in your R session: dir(path = \"~\", pattern = \".Renviron\", all.files = TRUE) That file should contain lines such as: DEFAULT_POSTGRES_PASSWORD=postgres DEFAULT_POSTGRES_USER_NAME=postgres Those are the PostreSQL default values for the username and password, so not secret. But this approach demonstrates how they would be kept secret and not uploaded to Github or some other public location when you need to keep credentials secret. This is how the sp_get_postgres_connection function is used: con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;postgres&quot;, seconds_to_test = 10) If you don’t have an .Rprofile file that defines those passwords, you can just insert a string for the parameter, like: password = 'whatever', Make sure that you can connect to the PostgreSQL database that you started earlier. If you have been executing the code from this tutorial, the database will not contain any tables yet: dbListTables(con) ## character(0) 4.3.2 Alternative: put the database password in an environment file The goal is to put the password in an untracked file that will not be committed in your source code repository. Your code can reference the name of the variable, but the value of that variable will not appear in open text in your source code. We have chosen to call the file dev_environment.csv in the current working directory where you are executing this script. That file name appears in the .gitignore file, so that you will not accidentally commit it. We are going to create that file now. You will be prompted for the database password. By default, a PostgreSQL database defines a database user named postgres, whose password is postgres. If you have changed the password or created a new user with a different password, then enter those new values when prompted. Otherwise, enter postgres and postgres at the two prompts. In an interactive environment, you could execute a snippet of code that prompts the user for their username and password with the following snippet (which isn’t run in the book): Your password is still in plain text in the file, dev_environment.csv, so you should protect that file from exposure. However, you do not need to worry about committing that file accidentally to your git repository, because the name of the file appears in the .gitignore file. For security, we use values from the environment_variables data.frame, rather than keeping the username and password in plain text in a source file. 4.3.3 Interact with Postgres Write mtcars to PostgreSQL dbWriteTable(con, &quot;mtcars&quot;, mtcars, overwrite = TRUE) List the tables in the PostgreSQL database to show that mtcars is now there: dbListTables(con) ## [1] &quot;mtcars&quot; # list the fields in mtcars: dbListFields(con, &quot;mtcars&quot;) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; Download the table from the DBMS to a local data frame: mtcars_df &lt;- tbl(con, &quot;mtcars&quot;) # Show a few rows: knitr::kable(head(mtcars_df)) mpg cyl disp hp drat wt qsec vs am gear carb 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 4.4 Clean up Afterwards, always disconnect from the DBMS, stop the docker container and (optionally) remove it. dbDisconnect(con) # tell Docker to stop the container: sp_docker_stop(&quot;cattle&quot;) ## [1] &quot;cattle&quot; # Tell Docker to remove the container from it&#39;s library of active containers: sp_docker_remove_container(&quot;cattle&quot;) ## [1] &quot;cattle&quot; If we stop the docker container but don’t remove it (with the rm cattle command), the container will persist and we can start it up again later with start cattle. In that case, mtcars would still be there and we could retrieve it from R again. Since we have now removed the cattle container, the whole database has been deleted. (There are enough copies of mtcars in the world, so no great loss.) "],
["a-persistent-database-in-postgres-in-docker-all-at-once-05.html", "Chapter 5 A persistent database in Postgres in Docker - all at once (05) 5.1 Overview 5.2 Verify that Docker is up and running 5.3 Clean up if appropriate 5.4 Build the Docker Image 5.5 Run the Docker Image 5.6 Connect to Postgres with R 5.7 Stop and start to demonstrate persistence 5.8 Cleaning up 5.9 Using the sql-pet container in the rest of the book", " Chapter 5 A persistent database in Postgres in Docker - all at once (05) At the end of this chapter, you will be able to Setup a database with “all in one” approach. Stop and start Docker image to demonstrate persistence Disconnect R from database and stop container to close up even though it still exists. 5.1 Overview You’ve already connected to PostgreSQL with R, now you need a “realistic” (dvdrental) database. We’re going to demonstrate how to set one up, with two different approaches. This chapter and the next do the same job, illustrating the different approaches that you can take and helping you see the different points where you could swap what’s provided here with a different DBMS or a different backup file or something else. The code in this first version is recommended because it is an “all in one” approach. Details about how it works and how you might modify it are included below. There is another version in the the next chapter that you can use to investigate Docker commands and components. Note that tidyverse, DBI, RPostgres, and glue are loaded. 5.2 Verify that Docker is up and running sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;6fd0fbdcf9f6 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; 27 minutes ago Up 26 minutes 0.0.0.0:5432-&gt;5432/tcp sql-pet&quot; 5.3 Clean up if appropriate Remove the sql-pet container if it exists (e.g., from a prior run) sp_docker_remove_container(&quot;sql-pet&quot;) ## Warning in system2(&quot;docker&quot;, docker_command, stdout = TRUE, stderr = TRUE): ## running command &#39;&#39;docker&#39; rm sql-pet 2&gt;&amp;1&#39; had status 1 ## [1] &quot;Error response from daemon: You cannot remove a running container 6fd0fbdcf9f67d0b2bbf47a167b29f3624a643b4ba7cc89b1b1c09e5e5a9f4c0. Stop the container before attempting removal or force remove&quot; ## attr(,&quot;status&quot;) ## [1] 1 5.4 Build the Docker Image Build an image that derives from postgres:10, defined in dvdrental.Dockerfile, that is set up to restore and load the dvdrental db on startup. The dvdrental.Dockerfile is discussed below. system2(&quot;docker&quot;, glue(&quot;build &quot;, # tells Docker to build an image that can be loaded as a container &quot;--tag postgres-dvdrental &quot;, # (or -t) tells Docker to name the image &quot;--file dvdrental.Dockerfile &quot;, #(or -f) tells Docker to read `build` instructions from the dvdrental.Dockerfile &quot; . &quot;), # tells Docker to look for dvdrental.Dockerfile in the current directory stdout = TRUE, stderr = TRUE) ## [1] &quot;Sending build context to Docker daemon 29.04MB\\r\\r&quot; ## [2] &quot;Step 1/4 : FROM postgres:10&quot; ## [3] &quot; ---&gt; ac25c2bac3c4&quot; ## [4] &quot;Step 2/4 : WORKDIR /tmp&quot; ## [5] &quot; ---&gt; Using cache&quot; ## [6] &quot; ---&gt; 3f00a18e0bdf&quot; ## [7] &quot;Step 3/4 : COPY init-dvdrental.sh /docker-entrypoint-initdb.d/&quot; ## [8] &quot; ---&gt; Using cache&quot; ## [9] &quot; ---&gt; 3453d61d8e3e&quot; ## [10] &quot;Step 4/4 : RUN apt-get -qq update &amp;&amp; apt-get install -y -qq curl zip &gt; /dev/null 2&gt;&amp;1 &amp;&amp; curl -Os http://www.postgresqltutorial.com/wp-content/uploads/2017/10/dvdrental.zip &amp;&amp; unzip dvdrental.zip &amp;&amp; rm dvdrental.zip &amp;&amp; chmod ugo+w dvdrental.tar &amp;&amp; chown postgres dvdrental.tar &amp;&amp; chmod u+x /docker-entrypoint-initdb.d/init-dvdrental.sh &amp;&amp; apt-get remove -y curl zip&quot; ## [11] &quot; ---&gt; Using cache&quot; ## [12] &quot; ---&gt; f5e93aa64875&quot; ## [13] &quot;Successfully built f5e93aa64875&quot; ## [14] &quot;Successfully tagged postgres-dvdrental:latest&quot; 5.5 Run the Docker Image Run docker to bring up postgres. The first time it runs it will take a minute to create the PostgreSQL environment. There are two important parts to this that may not be obvious: The source= parameter points to dvdrental.Dockerfile, which does most of the heavy lifting. It has detailed, line-by-line comments to explain what it is doing. Inside dvdrental.Dockerfile the command COPY init-dvdrental.sh /docker-entrypoint-initdb.d/ copies init-dvdrental.sh from the local file system into the specified location in the Docker container. When the PostgreSQL Docker container initializes, it looks for that file and executes it. Doing all of that work behind the scenes involves two layers of complexity. Depending on how you look at it, that may be more or less difficult to understand than the method shown in the next Chapter. wd &lt;- getwd() docker_cmd &lt;- glue( &quot;run &quot;, # Run is the Docker command. Everything that follows are `run` parameters. &quot;--detach &quot;, # (or `-d`) tells Docker to disconnect from the terminal / program issuing the command &quot; --name sql-pet &quot;, # tells Docker to give the container a name: `sql-pet` &quot;--publish 5432:5432 &quot;, # tells Docker to expose the Postgres port 5432 to the local network with 5432 &quot;--mount &quot;, # tells Docker to mount a volume -- mapping Docker&#39;s internal file structure to the host file structure &quot;type=bind,&quot;, # tells Docker that the mount command points to an actual file on the host system &#39;source=&quot;&#39;, # tells Docker where the local file will be found wd, &#39;/&quot;,&#39;, # the current working directory, as retrieved above &quot;target=/petdir&quot;, # tells Docker to refer to the current directory as &quot;/petdir&quot; in its file system &quot; postgres-dvdrental&quot; # tells Docker to run the image was built in the previous step ) # if you are curious you can paste this string into a terminal window after the command &#39;docker&#39;: docker_cmd ## run --detach --name sql-pet --publish 5432:5432 --mount type=bind,source=&quot;/Users/jds/Documents/Library/R/r-system/sql-pet/&quot;,target=/petdir postgres-dvdrental system2(&quot;docker&quot;, docker_cmd, stdout = TRUE, stderr = TRUE) ## Warning in system2(&quot;docker&quot;, docker_cmd, stdout = TRUE, stderr = TRUE): ## running command &#39;&#39;docker&#39; run --detach --name sql-pet --publish 5432:5432 ## --mount type=bind,source=&quot;/Users/jds/Documents/Library/R/r-system/sql- ## pet/&quot;,target=/petdir postgres-dvdrental 2&gt;&amp;1&#39; had status 125 ## [1] &quot;docker: Error response from daemon: Conflict. The container name \\&quot;/sql-pet\\&quot; is already in use by container \\&quot;6fd0fbdcf9f67d0b2bbf47a167b29f3624a643b4ba7cc89b1b1c09e5e5a9f4c0\\&quot;. You have to remove (or rename) that container to be able to reuse that name.&quot; ## [2] &quot;See &#39;docker run --help&#39;.&quot; ## attr(,&quot;status&quot;) ## [1] 125 5.6 Connect to Postgres with R Use the DBI package to connect to PostgreSQL. But first, wait for Docker &amp; PostgreSQL to come up before connecting. We have loaded the wait_for_postgres function behind the scenes. con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) dbListTables(con) ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; dbDisconnect(con) 5.7 Stop and start to demonstrate persistence Stop the container sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; Restart the container and verify that the dvdrental tables are still there sp_docker_start(&quot;sql-pet&quot;) con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) glimpse(dbReadTable(con, &quot;film&quot;)) ## Observations: 1,000 ## Variables: 13 ## $ film_id &lt;int&gt; 133, 384, 8, 98, 1, 2, 3, 4, 5, 6, 7, 9, 10, ... ## $ title &lt;chr&gt; &quot;Chamber Italian&quot;, &quot;Grosse Wonderful&quot;, &quot;Airpo... ## $ description &lt;chr&gt; &quot;A Fateful Reflection of a Moose And a Husban... ## $ release_year &lt;int&gt; 2006, 2006, 2006, 2006, 2006, 2006, 2006, 200... ## $ language_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... ## $ rental_duration &lt;int&gt; 7, 5, 6, 4, 6, 3, 7, 5, 6, 3, 6, 3, 6, 6, 6, ... ## $ rental_rate &lt;dbl&gt; 4.99, 4.99, 4.99, 4.99, 0.99, 4.99, 2.99, 2.9... ## $ length &lt;int&gt; 117, 49, 54, 73, 86, 48, 50, 117, 130, 169, 6... ## $ replacement_cost &lt;dbl&gt; 14.99, 19.99, 15.99, 12.99, 20.99, 12.99, 18.... ## $ rating &lt;chr&gt; &quot;NC-17&quot;, &quot;R&quot;, &quot;R&quot;, &quot;PG-13&quot;, &quot;PG&quot;, &quot;G&quot;, &quot;NC-17... ## $ last_update &lt;dttm&gt; 2013-05-26 14:50:58, 2013-05-26 14:50:58, 20... ## $ special_features &lt;chr&gt; &quot;{Trailers}&quot;, &quot;{\\&quot;Behind the Scenes\\&quot;}&quot;, &quot;{Tr... ## $ fulltext &lt;chr&gt; &quot;&#39;chamber&#39;:1 &#39;fate&#39;:4 &#39;husband&#39;:11 &#39;italian&#39;:... 5.8 Cleaning up It’s always good to have R disconnect from the database dbDisconnect(con) Stop the container and show that the container is still there, so can be started again. sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; # show that the container still exists even though it&#39;s not running sp_show_all_docker_containers() ## [1] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [2] &quot;6fd0fbdcf9f6 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; 27 minutes ago Exited (0) Less than a second ago sql-pet&quot; Next time, you can just use this command to start the container: sp_docker_start(&quot;sql-pet&quot;) And once stopped, the container can be removed with: sp_check_that_docker_is_up(&quot;sql-pet) 5.9 Using the sql-pet container in the rest of the book After this point in the book, we assume that Docker is up and that we can always start up our sql-pet database with: sp_docker_stop(&quot;sql-pet&quot;) "],
["mapping-your-local-environment-10.html", "Chapter 6 Mapping your local environment (10) 6.1 Basics 6.2 Ask yourself, what are you aiming for? 6.3 Get some basic information about your database 6.4 Tutorial Environment 6.5 Communicating with Docker Applications 6.6 Exercises", " Chapter 6 Mapping your local environment (10) 6.1 Basics Keeping passwords secure. Coverage in this book. There are many SQL tutorials that are available. For example, we are drawing some materials from a tutorial we recommend. In particular, we will not replicate the lessons there, which you might want to complete. Instead, we are showing strategies that are recommended for R users. That will include some translations of queries that are discussed there. 6.2 Ask yourself, what are you aiming for? Differences between production and data warehouse environments. Learning to keep your DBAs happy: You are your own DBA in this simulation, so you can wreak havoc and learn from it, but you can learn to be DBA-friendly here. In the end it’s the subject-matter experts that understand your data, but you have to work with your DBAs first. 6.3 Get some basic information about your database Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 The following code block confirms that one can connect to the Postgres database. The connection is needed for some of the examples/exercises used in this section. If the connection is successful, the output is &lt;PostgreSQLConnection&gt;. 6.4 Tutorial Environment Below is a high level diagram of our tutorial environment. The single black or blue boxed items are the apps running on your PC, (Linux, Mac, Windows), RStudio, R, Docker, and CLI, a command line interface. The red boxed items are the versions of the applications shown. The labels are to the right of the line. 6.5 Communicating with Docker Applications One assumption we made is that most users use RStudio to interface with R. The four take aways from the diagram above are labeled: dbConnect R-SQL processing, the purpose of this tutorial, is performed via a database connection. This should be a simple task, but often turns out to take a lot of time to actually get it to work. We assume that your final write ups are done in some flavor of an Rmd document and others will have access to the database to confirm or further your analysis. For this tutorial, the following are the hardcoded values used to make the Postgres database connection. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) The main focus of the entire tutorial is SQL processing through a dbConnection. The remainder of this section focuses on some specific Docker commands. bash The Docker container runs on top of a small Linux kernel foot print. Since Mac and Linux users run a version of Linux already, they may want to poke around the Docker environment. Below is the CLI command to start up a bash session, execute a version of hello world, and exit the bash session. c:\\Git\\sql-pet&gt;docker exec -ti sql-pet bash root@7e43294b72cf:/# echo &quot;&#39;hello world&#39;&quot; talking to you live from a bash shell session within Docker! &#39;hello world&#39; talking to you live from a bash shell session within Docker! root@7e43294b72cf:/# exit exit Note that the user in the example is root. Root has all priviledges and can destroy the Docker environment. psql For users comfortable executing SQL from a command line directly against the database, one can run the psql application directly. Below is the CLI command to start up psql session, execute a version of hello world, and quitting the psql version. c:\\Git\\sql-pet&gt;docker exec -ti sql-pet psql -a -p 5432 -d dvdrental -U postgres psql (10.5 (Debian 10.5-1.pgdg90+1)) Type &quot;help&quot; for help. dvdrental=# select &#39;&quot;hello world&quot; talking to you live from postgres session within Docker!&#39; hello; hello ------------------------------------------------------------------------ &quot;hello world&quot; talking to you live from postgres session within Docker! (1 row) dvdrental=# \\q All SQL commands need to end with a semi-colon. To exit psql, use a ‘’ at the command prompt. The docker bash and psql command options are optional for this tutorial, but open up a gateway to some very powerful programming techniques for future exploration. start-stop Docker has about 44 commands. We are interested in only those related to Postgres status, started, stopped, and available. In this tutorial, complete docker commands are printed out before being executed via a system2 call. In the event that a code block fails, one can copy and paste the docker command into your local CLI and see if Docker is returning additional information. 6.6 Exercises Docker containers have a small foot print. In our container, we are running a limited Linux kernel and a Postgres database. To show how tiny the docker environment is, we will look at all the processes running inside Docker and the top level file structure. 6.6.1 Docker Help Typing docker at the command line will print up a summary of all available docker commands. Below are the docker commands used in the exercises. Commands: ps List containers start Start one or more stopped containers stop Stop one or more running containers The general format for a Docker command is docker [OPTIONS] COMMAND ARGUMENTS Below is the output for the Docker exec help command which was used in the bash and psql command examples above and for an exercise below. C:\\Users\\SMY&gt;docker help exec Usage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...] Run a command in a running container Options: -d, --detach Detached mode: run command in the background --detach-keys string Override the key sequence for detaching a container -e, --env list Set environment variables -i, --interactive Keep STDIN open even if not attached --privileged Give extended privileges to the command -t, --tty Allocate a pseudo-TTY -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) -w, --workdir string Working directory inside the container In these exercies, the -i option and the CONTAINER = sql-pet are used in two of the exercises. Start up R/RStudio and convert the CLI command to an R/RStudio command # Question Docker CLI Command R RStudio command Local Command LINE 1 How many processes are running inside the Docker container? docker exec -i sql-pet ps -eF 1a How many process are running on your local machine? widows: tasklist Mac/Linux: ps -ef 2 What is the total number of files and directories in Docker? docker exec -i sql-pet ls -al 2a What is the total number of files and directories on your local machine? 3 Is Docker Running? docker version 3a What are your Client and Server Versions? 4 Does Postgres exist in the container? docker ps -a 4a What is the status of Postgres? docker ps -a 4b What is the size of Postgres? docker ps -a 4c What is the size of your laptop OS https://www.quora.com/What-is-the-actual-size-of-Windows-10-ISO-file 5 If sql-pet status is Up, How do I stop it? docker stop sql-pet 5a If sql-pet status is Exited, How do I start it? docker start sql-pet "],
["simple-queries-11.html", "Chapter 7 Simple queries (11) 7.1 Some extra handy libraries 7.2 Basic investigation 7.3 Using dplyr 7.4 What is dplyr sending to the server? 7.5 Writing SQL queries directly to the DBMS 7.6 Choosing between dplyr and native SQL", " Chapter 7 Simple queries (11) Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) 7.1 Some extra handy libraries https://dbplyr.tidyverse.org/articles/sql-translation.html Here are some packages that we find handy in the preliminary investigation of a database (or a problem that involves data from a database). library(glue) library(skimr) ## ## Attaching package: &#39;skimr&#39; ## The following object is masked from &#39;package:knitr&#39;: ## ## kable library(DT) 7.2 Basic investigation Need both familiarity with the data and a focus question An interative process Each informs the other R tools for data investigation glimpse str View and kable overview investigation: do you understand your data documentation and its limits what’s missing from the database: (columns, records, cells) find out how the data is used by those who enter it and others who’ve used it before why is there missing data? 7.3 Using dplyr We already started, but that’s OK. 7.3.1 Finding out what’s in the database DBI / RPostgres packages R tools like glimpse, skimr, kable. Tutorials like: https://suzan.rbind.io/tags/dplyr/ Benjamin S. Baumer, A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data: https://arxiv.org/pdf/1708.07073 7.3.2 Sample query rental date subset 7.3.3 Subset: only retrieve what you need Columns Rows number of row specific rows Counts &amp; stats 7.3.4 Make the server do as much work as you can discuss this simple example? http://www.postgresqltutorial.com/postgresql-left-join/ dplyr joins on the server side Where you put (collect(n = Inf)) really matters 7.4 What is dplyr sending to the server? show_query as a first draft 7.5 Writing SQL queries directly to the DBMS dbquery Glue for constructing SQL statements parameterizing SQL queries 7.6 Choosing between dplyr and native SQL performance considerations: first get the right data, then worry about performance Trade offs between leaving the data in PostgreSQL vs what’s kept in R: browsing the data larger samples and complete tables 7.6 using what you know to write efficient queries that do most of the work on the server dplyr_summary_df &lt;- read.delim( &#39;11-dplyr_sql_summary_table.tsv&#39;, header = TRUE, sep = &#39;\\t&#39;, as.is = TRUE ) if (MODE == &#39;DEMO&#39;) { View(dplyr_summary_df) } else { kable(head(dplyr_summary_df)) # DT::datatable(dplyr_summary_df) # a very nice display in some cases, but not in a PDF } In Dplyr_Function description SQL_Clause Notes Category Y arrange() Arrange rows by variables ORDER BY NA Basic single-table verbs Y? distinct() Return rows with matching conditions SELECT distinct * NA Basic single-table verbs Y select() rename() Select/rename variables by name SELECT column_name alias_name NA Basic single-table verbs N pull() Pull out a single variable SELECT column_name; NA Basic single-table verbs Y mutate() transmute() Add new variables SELECT computed_value computed_name NA Basic single-table verbs Y summarise() summarize() Reduces multiple values down to a single value SELECT aggregate_functions GROUP BY NA Basic single-table verbs * left join staff * left join customer * dplyr joins in the R r sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; # Joins and complex queries (13) ## Verify Docker is up and running: r sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; verify pet DB is available, it may be stopped. r sp_show_all_docker_containers() ## [1] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [2] &quot;6fd0fbdcf9f6 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; 27 minutes ago Exited (137) 2 seconds ago sql-pet&quot; Start up the docker-pet container r sp_docker_start(&quot;sql-pet&quot;) now connect to the database with R ```r # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection(user = Sys.getenv(“DEFAULT_POSTGRES_USER_NAME”), password = Sys.getenv(“DEFAULT_POSTGRES_PASSWORD”), dbname = “dvdrental”, seconds_to_test = 10) ``` ```r ## select examples ## dbGetQuery returns the entire result set as a data frame. ## For large returned datasets, complex or inefficient SQL statements, this may take a ## long time. ## dbSendQuery: parses, compiles, creates the optimized execution plan. ## dbFetch: Execute optimzed execution plan and return the dataset. ## dbClearResult:remove pending query results from the database to your R environment ``` How many customers are there in the DVD Rental System r rs1 &lt;- dbGetQuery(con, 'select * from customer;') kable(head(rs1)) customer_id store_id first_name last_name email address_id activebool create_date last_update active 524 1 Jared Ely jared.ely@sakilacustomer.org 530 TRUE 2006-02-14 2013-05-26 14:49:45 1 1 1 Mary Smith mary.smith@sakilacustomer.org 5 TRUE 2006-02-14 2013-05-26 14:49:45 1 2 1 Patricia Johnson patricia.johnson@sakilacustomer.org 6 TRUE 2006-02-14 2013-05-26 14:49:45 1 3 1 Linda Williams linda.williams@sakilacustomer.org 7 TRUE 2006-02-14 2013-05-26 14:49:45 1 4 2 Barbara Jones barbara.jones@sakilacustomer.org 8 TRUE 2006-02-14 2013-05-26 14:49:45 1 5 1 Elizabeth Brown elizabeth.brown@sakilacustomer.org 9 TRUE 2006-02-14 2013-05-26 14:49:45 1 pco &lt;- dbSendQuery(con, &#39;select * from customer;&#39;) rs2 &lt;- dbFetch(pco) dbClearResult(pco) kable(head(rs2)) customer_id store_id first_name last_name email address_id activebool create_date last_update active 524 1 Jared Ely jared.ely@sakilacustomer.org 530 TRUE 2006-02-14 2013-05-26 14:49:45 1 1 1 Mary Smith mary.smith@sakilacustomer.org 5 TRUE 2006-02-14 2013-05-26 14:49:45 1 2 1 Patricia Johnson patricia.johnson@sakilacustomer.org 6 TRUE 2006-02-14 2013-05-26 14:49:45 1 3 1 Linda Williams linda.williams@sakilacustomer.org 7 TRUE 2006-02-14 2013-05-26 14:49:45 1 4 2 Barbara Jones barbara.jones@sakilacustomer.org 8 TRUE 2006-02-14 2013-05-26 14:49:45 1 5 1 Elizabeth Brown elizabeth.brown@sakilacustomer.org 9 TRUE 2006-02-14 2013-05-26 14:49:45 1 # insert yourself as a new customer dbExecute(con, &quot;insert into customer (store_id,first_name,last_name,email,address_id ,activebool,create_date,last_update,active) values(2,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;dodreamdo@yahoo.com&#39;,1,TRUE,&#39;2018-09-13&#39;,&#39;2018-09-13&#39;,1) returning customer_id; &quot; ) ## [1] 0 ## anti join -- Find customers who have never rented a movie. rs &lt;- dbGetQuery(con, &quot;select c.first_name ,c.last_name ,c.email from customer c left outer join rental r on c.customer_id = r.customer_id where r.rental_id is null; &quot; ) head(rs) ## first_name last_name email ## 1 Sophie Yang dodreamdo@yahoo.com ## how many films and languages exist in the DVD rental application rs &lt;- dbGetQuery(con, &quot; select &#39;film&#39; table_name,count(*) count from film union select &#39;language&#39; table_name,count(*) count from language ; &quot; ) head(rs) ## table_name count ## 1 film 1000 ## 2 language 6 ## what is the film distribution based on language rs &lt;- dbGetQuery(con, &quot;select l.language_id id ,l.name ,sum(case when f.language_id is not null then 1 else 0 end) total from language l full outer join film f on l.language_id = f.language_id group by l.language_id,l.name order by l.name; ; &quot; ) head(rs) ## id name total ## 1 1 English 1000 ## 2 5 French 0 ## 3 6 German 0 ## 4 2 Italian 0 ## 5 3 Japanese 0 ## 6 4 Mandarin 0 ## Store analysis ### which store has had more rentals and income rs &lt;- dbGetQuery(con, &quot;select * from ( select &#39;actor&#39; tbl_name,count(*) from actor union select &#39;category&#39; tbl_name,count(*) from category union select &#39;film&#39; tbl_name,count(*) from film union select &#39;film_actor&#39; tbl_name,count(*) from film_actor union select &#39;film_category&#39; tbl_name,count(*) from film_category union select &#39;language&#39; tbl_name,count(*) from language union select &#39;inventory&#39; tbl_name,count(*) from inventory union select &#39;rental&#39; tbl_name,count(*) from rental union select &#39;payment&#39; tbl_name,count(*) from payment union select &#39;staff&#39; tbl_name,count(*) from staff union select &#39;customer&#39; tbl_name,count(*) from customer union select &#39;address&#39; tbl_name,count(*) from address union select &#39;city&#39; tbl_name,count(*) from city union select &#39;country&#39; tbl_name,count(*) from country union select &#39;store&#39; tbl_name,count(*) from store ) counts order by tbl_name ; &quot; ) head(rs) ## tbl_name count ## 1 actor 200 ## 2 address 603 ## 3 category 16 ## 4 city 600 ## 5 country 109 ## 6 customer 600 ## Store analysis ### which store has the largest income stream rs &lt;- dbGetQuery(con, &quot;select store_id,sum(amount) amt,count(*) cnt from payment p join staff s on p.staff_id = s.staff_id group by store_id order by 2 desc ; &quot; ) head(rs) ## store_id amt cnt ## 1 2 31059.92 7304 ## 2 1 30252.12 7292 ## Store analysis ### How many rentals have not been paid ### How many rentals have been paid ### How much has been paid ### What is the average price/movie ### Estimate the outstanding balance rs &lt;- dbGetQuery(con, &quot;select sum(case when payment_id is null then 1 else 0 end) missing ,sum(case when payment_id is not null then 1 else 0 end) found ,sum(p.amount) amt ,count(*) cnt ,round(sum(p.amount)/sum(case when payment_id is not null then 1 else 0 end),2) avg_price ,round(round(sum(p.amount)/sum(case when payment_id is not null then 1 else 0 end),2) * sum(case when payment_id is null then 1 else 0 end),2) est_balance from rental r left outer join payment p on r.rental_id = p.rental_id ; &quot; ) head(rs) ## missing found amt cnt avg_price est_balance ## 1 1452 14596 61312.04 16048 4.2 6098.4 ### what is the actual outstanding balance rs &lt;- dbGetQuery(con, &quot;select sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where p.rental_id is null ;&quot; ) head(rs) ## open_amt count ## 1 4297.48 1452 ### Rank customers with highest open amounts rs &lt;- dbGetQuery(con, &quot;select c.customer_id,c.first_name,c.last_name,sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join customer c on r.customer_id = c.customer_id where p.rental_id is null group by c.customer_id,c.first_name,c.last_name order by open_amt desc limit 25 ;&quot; ) head(rs) ## customer_id first_name last_name open_amt count ## 1 293 Mae Fletcher 35.90 10 ## 2 307 Joseph Joy 31.90 10 ## 3 316 Steven Curley 31.90 10 ## 4 299 James Gannon 30.91 9 ## 5 274 Naomi Jennings 29.92 8 ## 6 326 Jose Andrew 28.93 7 ### what film has been rented the most rs &lt;- dbGetQuery(con, &quot;select i.film_id,f.title,rental_rate,sum(rental_rate) revenue,count(*) count --16044 from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by i.film_id,f.title,rental_rate order by count desc ;&quot; ) head(rs) ## film_id title rental_rate revenue count ## 1 103 Bucket Brotherhood 4.99 169.66 34 ## 2 738 Rocketeer Mother 0.99 32.67 33 ## 3 331 Forward Temple 2.99 95.68 32 ## 4 767 Scalawag Duck 4.99 159.68 32 ## 5 382 Grit Clockwork 0.99 31.68 32 ## 6 489 Juggler Hardly 0.99 31.68 32 ### what film has been generated the most revenue assuming all amounts are collected rs &lt;- dbGetQuery(con, &quot;select i.film_id,f.title,rental_rate ,sum(rental_rate) revenue,count(*) count --16044 from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by i.film_id,f.title,rental_rate order by revenue desc ;&quot; ) head(rs) ## film_id title rental_rate revenue count ## 1 103 Bucket Brotherhood 4.99 169.66 34 ## 2 767 Scalawag Duck 4.99 159.68 32 ## 3 973 Wife Turn 4.99 154.69 31 ## 4 369 Goodfellas Salute 4.99 154.69 31 ## 5 1000 Zorro Ark 4.99 154.69 31 ## 6 31 Apache Divine 4.99 154.69 31 ### which films are in one store but not the other. rs &lt;- dbGetQuery(con, &quot;select coalesce(i1.film_id,i2.film_id) film_id ,f.title,f.rental_rate,i1.store_id,i1.count,i2.store_id,i2.count from (select film_id,store_id,count(*) count from inventory where store_id = 1 group by film_id,store_id) as i1 full outer join (select film_id,store_id,count(*) count from inventory where store_id = 2 group by film_id,store_id ) as i2 on i1.film_id = i2.film_id join film f on coalesce(i1.film_id,i2.film_id) = f.film_id where i1.film_id is null or i2.film_id is null order by f.title ; &quot; ) head(rs) ## film_id title rental_rate store_id count store_id..6 ## 1 2 Ace Goldfinger 4.99 NA &lt;NA&gt; 2 ## 2 3 Adaptation Holes 2.99 NA &lt;NA&gt; 2 ## 3 5 African Egg 2.99 NA &lt;NA&gt; 2 ## 4 8 Airport Pollock 4.99 NA &lt;NA&gt; 2 ## 5 13 Ali Forever 4.99 NA &lt;NA&gt; 2 ## 6 20 Amelie Hellfighters 4.99 1 3 NA ## count..7 ## 1 3 ## 2 4 ## 3 3 ## 4 4 ## 5 4 ## 6 &lt;NA&gt; # Compute the outstanding balance. rs &lt;- dbGetQuery(con, &quot;select sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where p.rental_id is null ;&quot; ) head(rs) ## open_amt count ## 1 4297.48 1452 list what’s there dbListTables(con) ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; Clean up # dbRemoveTable(con, &quot;cars&quot;) # dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; "],
["sql-quick-start-simple-retrieval-15.html", "Chapter 8 SQL Quick start - simple retrieval (15) 8.1 SQL Commands 8.2 Query statement structure 8.3 SQL Clauses 8.4 SELECT Clause: Column Selection – Vertical Partioning of Data 8.5 SQL Comments 8.6 FROM Clause 8.7 WHERE Clause: Row Selection – Horizontal Partitioning of Data 8.8 TO-DO’s", " Chapter 8 SQL Quick start - simple retrieval (15) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 colFmt &lt;- function(x,color) { # x string # color outputFormat = knitr::opts_knit$get(&quot;rmarkdown.pandoc.to&quot;) if(outputFormat == &#39;latex&#39;) paste(&quot;\\\\textcolor{&quot;,color,&quot;}{&quot;,x,&quot;}&quot;,sep=&quot;&quot;) else if(outputFormat == &#39;html&#39;) paste(&quot;&lt;font color=&#39;&quot;,color,&quot;&#39;&gt;&quot;,x,&quot;&lt;/font&gt;&quot;,sep=&quot;&quot;) else x } # sample call # * `r colFmt(&#39;Cover inline tables in future section&#39;,&#39;red&#39;)` 8.1 SQL Commands SQL commands fall into four categories. SQL Category Definition DDL:Data Definition Language DBA’s execute these commands to define objects in the database. DML:Data Manipulation Language Users and developers execute these commands to investigate data. DCL:Data Control Language DBA’s execute these commands to grant/revoke access to TCL:Transaction Control Language Developers execute these commands when developing applications. Data analysts use the SELECT DML command to learn interesting things about the data stored in the database. Applications are used to control the insert, update, and deletion of data in the database. Data users can update the database objects via the application which enforces referential integrity in the database, but not directly against the application database objects. DBA’s can setup a sandbox within the database for a data analyst. The application(s) do not maintain the data in the sandbox. In addition to the SELECT command, data analysts may be granted any or all the commands in the DDL and DML sections in the table below. The most common ones are the DML commands with a star, &quot;*. &quot; DDL DML DCL TCL ALTER CALL GRANT COMMIT CREATE DELETE* REVOKE ROLLBACK DROP EXPLAIN PLAN SAVEPOINT RENAME INSERT* SET TRANSACTION TRUNCATE LOCK TABLE MERGE SELECT* UPDATE* Most relational database applications are designed for speed, speedy on-line transactional processing, OLTP, and a lot of parent child relationships. Such applications can have 100’s or even 1000’s of tables supporting the application. The goal is to transform the application data model into a useful data analysis model using the DDL and DML SQL statements. The sql-pet database is tiny, but for the purposes of these exercises, we assume that data so large that it will not easily fit into the memory of your laptop. A SQL SELECT statement consists of 1 to 6 clauses. In the table below, object refers to either a database table or a view object. SQL Clause DPLYR Verb SQL Description SELECT SELECT() Contains a list of column names from an object or a derived value. mutate() FROM Contains a list of related objects from which the SELECT list of columns is derived. WHERE filter() Provides the filter conditions the objects in the FROM clause must meet. GROUP BY group_by() Contains a list unique column values returned from the WHERE clause. HAVING Provides the filter condition on the the GROUP BY clause. ORDER BY arrange() Contains a list of column names indicating the order of the column value. Each column can be either ASCending or DEScending. 8.2 Query statement structure A SQL query statement consists of six distinct parts and each part is referred to as a clause. The foundation of the SQL language is based set theory and the result of a SQL query is referred to as a result set. A SQL query statement is “guaranteed” to return the same set of data, but not necessarily in the same order. However, in practice, the result set is usually in the same order. For this tutorial, a SQL query either returns a detailed row set or a summarized row set. The detailed row set can show, but is not required to show every column. A summarized row set requires one or more summary columns and the associated aggregated summary values. Sales reps may be interested a detailed sales report showing all their activity. At the end of the month, the sales rep may be interested at a summary level based on product line dollars. The sales manager may be more interest in territory dollars. 8.3 SQL Clauses Select Clause From Clause Where Clause Group By Clause Having Clause Order By Clause This section focuses on getting new SQL users familiar with the six SQL query clauses and a single table. SQL queries from multiple tables are discussed in the JOIN section of this tutorial. For lack of a better term, a SQL-QBE, a very simple SQL Query by example, is used to illustrate some SQL feature. Side Note: This version of Postgres requires all SQL statments be terminated with a semi-colon. Some older flavors of SQL and GUI tools do not require the SQL statement to be terminated with a semi-colon, ‘;’ for the command to be executed. It is recommended that you always terminate your SQL commands with a semi-colon. 8.4 SELECT Clause: Column Selection – Vertical Partioning of Data 8.4.1 1. Simplest SQL query: All rows and all columns from a single table. dvdrental=# select * from store; store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 8.4.2 2. Same Query as 1, but only show first two columns; dvdrental=# select STORE_ID, manager_staff_id from store; store_id manager_staff_id 1 1 2 2 8.4.3 3. Same Query as 2, but reverse the column order dvdrental=# select manager_staff_id,store_id from store; manager_staff_id store_id 1 1 2 2 8.4.4 4. Rename Columns – SQL column alias in the result set dvdrental=# select manager_staff_id mgr_sid,store_id &quot;store id&quot; from store; mgr_sid store id 1 1 2 2 The manager_staff_id has changed to mgr_sid. store_id has changed to store id. In practice, aliasing column names that have a space is not done. Note that the column names have changed in the result set only, not in the actual database table. The DBA&#39;s will not allow a space or other special characters in a database table column name. Some motivations for aliasing the result set column names are 1. Some database table column names are not user friendly. 2. When multiple tables are joined, the column names may be the same in one or more tables and one needs to distinguish between the column names from the different tables. 8.4.5 5. Adding labels and Additional Columns to the Result Set dvdrental=# select &#39;derived column&#39; showing ,* ,current_database() db ,user ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts from store; showing store_id manager_staff_id address_id last_update db user dtts derived column 1 1 1 2006-02-15 09:57:12 dvdrental postgres 2018/10/07 20:20:28 derived column 2 2 2 2006-02-15 09:57:12 dvdrental postgres 2018/10/07 20:20:28 All the previous examples easily fit on a single line. This one is longer. Each column is entered on its own line, indented past the select keyword, and preceeded by a comma. 1. The showing column is a hard coded string surrounded by single quotes. Note that single quotes are for hard coded values and double quotes are for column aliases. 2. The db and dtts, date timestamp, are new columns generated from Postgres System Information Functions. 3. Note that `user` is not a function call, no parenthesis. 8.5 SQL Comments https://pgexercises.com/questions/basic SQL supports both a single line comment, preceed the line with two dashes, --, and a C like block comment, \\* … */. 8.5.1 6. Single line comment – dvdrental=# select &#39;single line comment, dtts&#39; showing ,* ,current_database() db ,user -- ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts from store; showing store_id manager_staff_id address_id last_update db user single line comment, dtts 1 1 1 2006-02-15 09:57:12 dvdrental postgres single line comment, dtts 2 2 2 2006-02-15 09:57:12 dvdrental postgres The dtts line is commented out with the two dashes and is dropped from the end of the result set columns. 8.5.2 7. Multi-line comment /*…*/ dvdrental=# select &#39;block comment drop db, user, and dtts&#39; showing ,* /* ,current_database() db ,user ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts */ from store; showing store_id manager_staff_id address_id last_update block comment drop db, user, and dtts 1 1 1 2006-02-15 09:57:12 block comment drop db, user, and dtts 2 2 2 2006-02-15 09:57:12 The three columns db, user, and dtts, between the /\\* and \\*/ have been commented and no longer appear as the end columns of the result set. 8.6 FROM Clause The FROM clause contains database tables/views from which the SELECT columns are derived. For now, in the examples, we are only using a single table. If the database reflects a relational model, your data is likely spread out over several tables. The key take away when beginning your analysis is to pick the table that has most of the data that you need for your analysis. This table becomes your main or driving table to build your SQL query statement around. After identifying your driving table, potentially save yourself a lot of time and heart ache. Review any view that is built on your driving table. If one or more exist, especially if vendor built, may already have the additional information need for your analysis. Insert SQL here or link to Views dependent on what In this tutorial, there is only a single user hitting the database and row/table locking is not necessary and considered out of scope. 8.6.1 Table Uses A table can be used more than once in a FROM clause. These are self-referencing table. An example is an EMPLOYEE table which contains a foriegn key to her manager. Her manager also has a foriegn key to her manager, etc up the corporate ladder. In the example above, the EMPLOYEE table plays two roles, employee and manager. The next line shows the FROM clause showing both rows. FROM EMPLOYEE EE, EMPLOYEE MGR The EE and MGR are role abbreviations for the EMPLOYEE table. Since all the column names are exactly the same for the EE and MGR role, the column names need to be prefixed with their role alias, e.g., SELECT MGR.EE_NAME, EE.EE_NAME … shows the manager name and her employee name who work for her. It is a good habit to always alias your tables and prefix your column names with the table alias to eliminate any ambiguity as to where the column came from. This is critical where there is inconsistent table column naming convention. Cover inline tables in future section Side Note: Do not create an unintended Cartesian join. If one has more than one table in the FROM clause, make sure that every table in the FROM clause joins to at least one other table. If your result set has an unexpectantly high rowcount and long runtime, check for a missing join in the FROM clause. 8.7 WHERE Clause: Row Selection – Horizontal Partitioning of Data In the previous SELECT clause section, the SELECT statement either partitioned data vertically across the table columns or derived vertical column values. This section provides examples that partitions the table data across rows in the table. The WHERE clause defines all the conditions the data must meet to be included or excluded in the final result set. If all the conditions are met data is returned or it is rejected. This is commonly referred to as the data set filter condition. Side Note: For performance optimization reasons, the WHERE clause should reduce the dataset down to the smallest dataset as quickly as possible. This is typically done using indexed columns, range conditions, and any other condition that rejects a lot of rows from being retrieved. The WHERE condition(s) can be simple or complex, but in the end are the appliction of the logic rules shown in the table below. p q p and q p or q T T T T T F F T T N N T F F F F F N F T N N N N When the filter logic is complex, it is sometimes easier to represent the where clause symbollically and apply a version of DeMorgan’s law which is shown below. (A and B)’ = A’ or B’ (A or B)’ = A’ and B’ 8.7.1 Example Continued We begin with 1, our simplest SQL query. dvdrental=# select * from store; store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 8.7.2 7 WHERE condition logically never TRUE. dvdrental=# select * from store where 1 = 0; store_id manager_staff_id address_id last_update Since 1 = 0 is always false, no rows are ever returned. Initially this construct seems useless, but actually is quite handy when debugging large scripts where a portion of the script needs to be turned off or when creating an empty table with the exact same column names and types as the FROM table(s). 8.7.3 8 WHERE condition logically always TRUE. dvdrental=# select * from store where 1 = 1; store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 Since 1 = 1 is always true, all rows are always returned. Initially this construct seems useless, but actually is also quite handy when debugging large scripts and creating a backup of table. 8.7.4 9 WHERE equality condition dvdrental=# select * from store where store_id = 2; store_id manager_staff_id address_id last_update 2 2 2 2006-02-15 09:57:12 The only row where the store_id = 2 is row 2. Only row 2 is kept and all others are dropped. 8.7.5 10 WHERE NOT equal conditions dvdrental=# select * from store where store_id &lt;&gt; 2; # &lt;&gt; syntactically the same as != store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 The only row where the store_id &lt;&gt; 2 is row 1. Only row 1 is kept and all others are dropped. 8.7.6 10 WHERE OR condition dvdrental=# select * from store where manager_staff_id = 1 or store_id &lt;&gt; 2 or address_id = 3; Following table is modified from http://www.tutorialspoint.com/sql/sql-operators SQL Comparison Operators Operator Description example = Checks if the values of two operands are equal or not, if yes then condition becomes true. (a = b) is not true. != Checks if the values of two operands are equal or not, if values are not equal then condition becomes true. (a != b) is true. &lt;&gt; Checks if the values of two operands are equal or not, if values are not equal then condition becomes true. (a &lt;&gt; b) is true. &gt; Checks if the value of left operand is greater than the value of right operand, if yes then condition becomes true. (a &gt; b) is not true. &lt; Checks if the value of left operand is less than the value of right operand, if yes then condition becomes true. (a &lt; b) is true. &gt;= Checks if the value of left operand is greater than or equal to the value of right operand, if yes then condition becomes true. (a &gt;= b) is not true. &lt;= Checks if the value of left operand is less than or equal to the value of right operand, if yes then condition becomes true. (a &lt;= b) is true. !&lt; Checks if the value of left operand is not less than the value of right operand, if yes then condition becomes true. (a !&lt; b) is false. !&gt; Checks if the value of left operand is not greater than the value of right operand, if yes then condition becomes true. (a !&gt; b) is true. Operator Description ALL The ALL operator is used to compare a value to all values in another value set. AND The AND operator allows the existence of multiple conditions in an SQL statement’s WHERE clause. ANY The ANY operator is used to compare a value to any applicable value in the list as per the condition. BETWEEN The BETWEEN operator is used to search for values that are within a set of values, given the minimum value and the maximum value. EXISTS The EXISTS operator is used to search for the presence of a row in a specified table that meets a certain criterion. IN The IN operator is used to compare a value to a list of literal values that have been specified. LIKE The LIKE operator is used to compare a value to similar values using wildcard operators. NOT The NOT operator reverses the meaning of the logical operator with which it is used. Eg: NOT EXISTS, NOT BETWEEN, NOT IN, etc. This is a negate operator. OR The OR operator is used to combine multiple conditions in an SQL statement’s WHERE clause. IS NULL The NULL operator is used to compare a value with a NULL value. UNIQUE The UNIQUE operator searches every row of a specified table for uniqueness (no duplicates). 8.8 TO-DO’s inline tables correlated subqueries Binding order 3.1 FROM 3.2 ON 3.3 JOIN 3.4 WHERE 3.5 GROUP BY 3.6 WITH CUBE/ROLLUP 3.7 HAVING 3.8 SELECT 3.9 DISTINCT 3.10 ORDER BY 3.11 TOP 3.12 OFFSET/FETCH dplyr comparison of select features dplyr comparison of fetch versus where. SQL for View table dependencies. Add cartesian join exercise. "],
["getting-metadata-about-and-from-the-database-21.html", "Chapter 9 Getting metadata about and from the database (21) 9.1 Always look at the data 9.2 Database contents and structure 9.3 What columns do those tables contain? 9.4 Characterizing how things are named 9.5 Database keys 9.6 Creating your own data dictionary", " Chapter 9 Getting metadata about and from the database (21) Note that tidyverse, DBI, RPostgres, glue, and knitr are loaded. Also, we’ve sourced the db-login-batch-code.R file which is used to log in to PostgreSQL. Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10 ) 9.1 Always look at the data 9.1.1 Connect with people who own, generate, or are the subjects of the data A good chat with people who own the data, generate it, or are the subjects can generate insights and set the context for your investigation of the database. The purpose for collecting the data or circumsances where it was collected may be burried far afield in an organization, but usually someone knows. The metadata discussed in this chapter is essential but will only take you so far. 9.1.2 Browse a few rows of a table Simple tools like head or glimpse are your friend. rental &lt;- dplyr::tbl(con, &quot;rental&quot;) kable(head(rental)) rental_id rental_date inventory_id customer_id return_date staff_id last_update 2 2005-05-24 22:54:33 1525 459 2005-05-28 19:40:33 1 2006-02-16 02:30:53 3 2005-05-24 23:03:39 1711 408 2005-06-01 22:12:39 1 2006-02-16 02:30:53 4 2005-05-24 23:04:41 2452 333 2005-06-03 01:43:41 2 2006-02-16 02:30:53 5 2005-05-24 23:05:21 2079 222 2005-06-02 04:33:21 1 2006-02-16 02:30:53 6 2005-05-24 23:08:07 2792 549 2005-05-27 01:32:07 1 2006-02-16 02:30:53 7 2005-05-24 23:11:53 3995 269 2005-05-29 20:34:53 2 2006-02-16 02:30:53 glimpse(rental) ## Observations: ?? ## Variables: 7 ## $ rental_id &lt;int&gt; 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1... ## $ rental_date &lt;dttm&gt; 2005-05-24 22:54:33, 2005-05-24 23:03:39, 2005-0... ## $ inventory_id &lt;int&gt; 1525, 1711, 2452, 2079, 2792, 3995, 2346, 2580, 1... ## $ customer_id &lt;int&gt; 459, 408, 333, 222, 549, 269, 239, 126, 399, 142,... ## $ return_date &lt;dttm&gt; 2005-05-28 19:40:33, 2005-06-01 22:12:39, 2005-0... ## $ staff_id &lt;int&gt; 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2... ## $ last_update &lt;dttm&gt; 2006-02-16 02:30:53, 2006-02-16 02:30:53, 2006-0... 9.2 Database contents and structure 9.2.1 Database structure For large or complex databases, however, you need to use both the available documentation for your database (e.g., the dvdrental database) and the other empirical tools that are available. For example it’s worth learning to interpret the symbols in an Entity Relationship Diagram: The information_schema is a trove of information about the database. Its format is more or less consistent across the different SQL implementations that are available. Here we explore some of what’s available using several different methods. Postgres stores a lot of metadata. 9.2.2 Contents of the information_schema For this chapter R needs the dbplyr package to access alternate schemas. A schema is an object that contains one or more tables. Most often there will be a default schema, but to access the metadata, you need to explicitly specify which schema contains the data you want. 9.2.3 What tables are in the database? The simplest way to get a list of tables is with table_list &lt;- DBI::dbListTables(con) kable(table_list) x actor_info customer_list film_list nicer_but_slower_film_list sales_by_film_category staff sales_by_store staff_list category film_category country actor language inventory payment rental city store film address film_actor customer 9.2.4 Digging into the information_schema We usually need more detail than just a list of tables. Most SQL databases have am information_schema that has a standard structure to describe and control the database. The information_schema is in a different schema from the default, so to connect to the tables table in the information_schema we connect to the database in a different way: table_info_schema_table &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;tables&quot;)) The information_schema is large and complex and contains 210 tables. So it’s easy to get lost in it. This query retrieves a list of the tables in the database that includes additional detail, not just the name of the table. table_info &lt;- table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% select(table_catalog, table_schema, table_name, table_type) %&gt;% arrange(table_type, table_name) %&gt;% collect() kable(table_info) table_catalog table_schema table_name table_type dvdrental public actor BASE TABLE dvdrental public address BASE TABLE dvdrental public category BASE TABLE dvdrental public city BASE TABLE dvdrental public country BASE TABLE dvdrental public customer BASE TABLE dvdrental public film BASE TABLE dvdrental public film_actor BASE TABLE dvdrental public film_category BASE TABLE dvdrental public inventory BASE TABLE dvdrental public language BASE TABLE dvdrental public payment BASE TABLE dvdrental public rental BASE TABLE dvdrental public staff BASE TABLE dvdrental public store BASE TABLE dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public sales_by_store VIEW dvdrental public staff_list VIEW In this context table_catalog is synonymous with `database `. Notice that VIEWS are composites made up of one or more BASE TABLES. The SQL world has its own terminology. For example rs is shorthand for result set. That’s equivalent to using df for a data frame. The following SQL query returns the same information as the previous one. rs &lt;- dbGetQuery( con, &quot;select table_catalog, table_schema, table_name, table_type from information_schema.tables where table_schema not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) order by table_type, table_name ;&quot; ) kable(rs) table_catalog table_schema table_name table_type dvdrental public actor BASE TABLE dvdrental public address BASE TABLE dvdrental public category BASE TABLE dvdrental public city BASE TABLE dvdrental public country BASE TABLE dvdrental public customer BASE TABLE dvdrental public film BASE TABLE dvdrental public film_actor BASE TABLE dvdrental public film_category BASE TABLE dvdrental public inventory BASE TABLE dvdrental public language BASE TABLE dvdrental public payment BASE TABLE dvdrental public rental BASE TABLE dvdrental public staff BASE TABLE dvdrental public store BASE TABLE dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public sales_by_store VIEW dvdrental public staff_list VIEW 9.3 What columns do those tables contain? Of course, the DBI package has a dbListFields function that provides the simplest way to get the minimum, a list of column names: DBI::dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; But the information_schema has a lot more useful information that we can use. columns_info_schema_table &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;columns&quot;)) Since the information_schema contains 1855 columns, we are narrowing our focus to just one table. This query retrieves more information about the rental table: columns_info_schema_info &lt;- columns_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% select( table_catalog, table_schema, table_name, column_name, data_type, ordinal_position, character_maximum_length, column_default, numeric_precision, numeric_precision_radix ) %&gt;% collect(n = Inf) %&gt;% mutate(data_type = case_when( data_type == &quot;character varying&quot; ~ paste0(data_type, &#39; (&#39;, character_maximum_length, &#39;)&#39;), data_type == &quot;real&quot; ~ paste0(data_type, &#39; (&#39;, numeric_precision, &#39;,&#39;, numeric_precision_radix,&#39;)&#39;), TRUE ~ data_type) ) %&gt;% filter(table_name == &quot;rental&quot;) %&gt;% select(-table_schema, -numeric_precision, -numeric_precision_radix) glimpse(columns_info_schema_info) ## Observations: 7 ## Variables: 7 ## $ table_catalog &lt;chr&gt; &quot;dvdrental&quot;, &quot;dvdrental&quot;, &quot;dvdrental&quot;... ## $ table_name &lt;chr&gt; &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental... ## $ column_name &lt;chr&gt; &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventor... ## $ data_type &lt;chr&gt; &quot;integer&quot;, &quot;timestamp without time zo... ## $ ordinal_position &lt;int&gt; 1, 2, 3, 4, 5, 6, 7 ## $ character_maximum_length &lt;int&gt; NA, NA, NA, NA, NA, NA, NA ## $ column_default &lt;chr&gt; &quot;nextval(&#39;rental_rental_id_seq&#39;::regc... kable(columns_info_schema_info) table_catalog table_name column_name data_type ordinal_position character_maximum_length column_default dvdrental rental rental_id integer 1 NA nextval(‘rental_rental_id_seq’::regclass) dvdrental rental rental_date timestamp without time zone 2 NA NA dvdrental rental inventory_id integer 3 NA NA dvdrental rental customer_id smallint 4 NA NA dvdrental rental return_date timestamp without time zone 5 NA NA dvdrental rental staff_id smallint 6 NA NA dvdrental rental last_update timestamp without time zone 7 NA now() 9.3.1 What is the difference between a VIEW and a BASE TABLE? The BASE TABLE has the underlying data in the database table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot; &amp; table_type == &quot;BASE TABLE&quot;) %&gt;% select(table_name, table_type) %&gt;% left_join(columns_info_schema_table, by = c(&quot;table_name&quot; = &quot;table_name&quot;)) %&gt;% select( table_type, table_name, column_name, data_type, ordinal_position, column_default ) %&gt;% collect(n = Inf) %&gt;% filter(str_detect(table_name, &quot;cust&quot;)) %&gt;% kable() table_type table_name column_name data_type ordinal_position column_default BASE TABLE customer store_id smallint 2 NA BASE TABLE customer first_name character varying 3 NA BASE TABLE customer last_name character varying 4 NA BASE TABLE customer email character varying 5 NA BASE TABLE customer address_id smallint 6 NA BASE TABLE customer active integer 10 NA BASE TABLE customer customer_id integer 1 nextval(‘customer_customer_id_seq’::regclass) BASE TABLE customer activebool boolean 7 true BASE TABLE customer create_date date 8 (‘now’::text)::date BASE TABLE customer last_update timestamp without time zone 9 now() Probably should explore how the VIEW is made up of data from BASE TABLEs. table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot; &amp; table_type == &quot;VIEW&quot;) %&gt;% select(table_name, table_type) %&gt;% left_join(columns_info_schema_table, by = c(&quot;table_name&quot; = &quot;table_name&quot;)) %&gt;% select( table_type, table_name, column_name, data_type, ordinal_position, column_default ) %&gt;% collect(n = Inf) %&gt;% filter(str_detect(table_name, &quot;cust&quot;)) %&gt;% kable() table_type table_name column_name data_type ordinal_position column_default VIEW customer_list id integer 1 NA VIEW customer_list name text 2 NA VIEW customer_list address character varying 3 NA VIEW customer_list zip code character varying 4 NA VIEW customer_list phone character varying 5 NA VIEW customer_list city character varying 6 NA VIEW customer_list country character varying 7 NA VIEW customer_list notes text 8 NA VIEW customer_list sid smallint 9 NA 9.3.2 What data types are found in the database? columns_info_schema_info %&gt;% count(data_type) ## # A tibble: 3 x 2 ## data_type n ## &lt;chr&gt; &lt;int&gt; ## 1 integer 2 ## 2 smallint 2 ## 3 timestamp without time zone 3 9.4 Characterizing how things are named Names are the handle for accessing the data. Tables and columns may or may not be named consistently or in a way that makes sense to you. You should look at these names as data. 9.4.1 Counting columns and name reuse Pull out some rough-and-ready but useful statistics about your database. Since we are in SQL-land we talk about variables as columns. public_tables &lt;- columns_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% collect() public_tables %&gt;% count(table_name, sort = TRUE) %&gt;% kable() table_name n film 13 staff 11 customer 10 customer_list 9 address 8 film_list 8 nicer_but_slower_film_list 8 staff_list 8 rental 7 payment 6 actor 4 actor_info 4 city 4 inventory 4 store 4 category 3 country 3 film_actor 3 film_category 3 language 3 sales_by_store 3 sales_by_film_category 2 How many column names are shared across tables (or duplicated)? public_tables %&gt;% count(column_name, sort = TRUE) %&gt;% filter(n &gt; 1) ## # A tibble: 34 x 2 ## column_name n ## &lt;chr&gt; &lt;int&gt; ## 1 last_update 14 ## 2 address_id 4 ## 3 film_id 4 ## 4 first_name 4 ## 5 last_name 4 ## 6 name 4 ## 7 store_id 4 ## 8 actor_id 3 ## 9 address 3 ## 10 category 3 ## # ... with 24 more rows How many column names are unique? public_tables %&gt;% count(column_name) %&gt;% filter(n == 1) %&gt;% count() ## # A tibble: 1 x 1 ## nn ## &lt;int&gt; ## 1 24 9.5 Database keys 9.5.1 Direct SQL How do we use this output? Could it be generated by dplyr? rs &lt;- dbGetQuery( con, &quot; --SELECT conrelid::regclass as table_from select table_catalog||&#39;.&#39;||table_schema||&#39;.&#39;||table_name table_name , conname, pg_catalog.pg_get_constraintdef(r.oid, true) as condef FROM information_schema.columns c,pg_catalog.pg_constraint r WHERE 1 = 1 --r.conrelid = &#39;16485&#39; AND r.contype in (&#39;f&#39;,&#39;p&#39;) ORDER BY 1 ;&quot; ) glimpse(rs) ## Observations: 61,215 ## Variables: 3 ## $ table_name &lt;chr&gt; &quot;dvdrental.information_schema.administrable_role_au... ## $ conname &lt;chr&gt; &quot;actor_pkey&quot;, &quot;actor_pkey&quot;, &quot;actor_pkey&quot;, &quot;country_... ## $ condef &lt;chr&gt; &quot;PRIMARY KEY (actor_id)&quot;, &quot;PRIMARY KEY (actor_id)&quot;,... kable(head(rs)) table_name conname condef dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) The following is more compact and looks more useful. What is the difference bet ween the two? rs &lt;- dbGetQuery( con, &quot;select conrelid::regclass as table_from ,c.conname ,pg_get_constraintdef(c.oid) from pg_constraint c join pg_namespace n on n.oid = c.connamespace where c.contype in (&#39;f&#39;,&#39;p&#39;) and n.nspname = &#39;public&#39; order by conrelid::regclass::text, contype DESC; &quot; ) glimpse(rs) ## Observations: 33 ## Variables: 3 ## $ table_from &lt;chr&gt; &quot;actor&quot;, &quot;address&quot;, &quot;address&quot;, &quot;category&quot;... ## $ conname &lt;chr&gt; &quot;actor_pkey&quot;, &quot;address_pkey&quot;, &quot;fk_address... ## $ pg_get_constraintdef &lt;chr&gt; &quot;PRIMARY KEY (actor_id)&quot;, &quot;PRIMARY KEY (a... kable(head(rs)) table_from conname pg_get_constraintdef actor actor_pkey PRIMARY KEY (actor_id) address address_pkey PRIMARY KEY (address_id) address fk_address_city FOREIGN KEY (city_id) REFERENCES city(city_id) category category_pkey PRIMARY KEY (category_id) city city_pkey PRIMARY KEY (city_id) city fk_city FOREIGN KEY (country_id) REFERENCES country(country_id) dim(rs)[1] ## [1] 33 9.5.2 Database keys with dplyr This query shows the primary and foreign keys in the database. tables &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;tables&quot;)) table_constraints &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;table_constraints&quot;)) key_column_usage &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;key_column_usage&quot;)) referential_constraints &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;referential_constraints&quot;)) constraint_column_usage &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;constraint_column_usage&quot;)) keys &lt;- tables %&gt;% left_join(table_constraints, by = c( &quot;table_catalog&quot; = &quot;table_catalog&quot;, &quot;table_schema&quot; = &quot;table_schema&quot;, &quot;table_name&quot; = &quot;table_name&quot; )) %&gt;% # table_constraints %&gt;% filter(constraint_type %in% c(&quot;FOREIGN KEY&quot;, &quot;PRIMARY KEY&quot;)) %&gt;% left_join(key_column_usage, by = c( &quot;table_catalog&quot; = &quot;table_catalog&quot;, &quot;constraint_catalog&quot; = &quot;constraint_catalog&quot;, &quot;constraint_schema&quot; = &quot;constraint_schema&quot;, &quot;table_name&quot; = &quot;table_name&quot;, &quot;table_schema&quot; = &quot;table_schema&quot;, &quot;constraint_name&quot; = &quot;constraint_name&quot; )) %&gt;% # left_join(constraint_column_usage) %&gt;% # does this table add anything useful? select(table_name, table_type, constraint_name, constraint_type, column_name, ordinal_position) %&gt;% arrange(table_name) %&gt;% collect() glimpse(keys) ## Observations: 35 ## Variables: 6 ## $ table_name &lt;chr&gt; &quot;actor&quot;, &quot;address&quot;, &quot;address&quot;, &quot;category&quot;, &quot;c... ## $ table_type &lt;chr&gt; &quot;BASE TABLE&quot;, &quot;BASE TABLE&quot;, &quot;BASE TABLE&quot;, &quot;BA... ## $ constraint_name &lt;chr&gt; &quot;actor_pkey&quot;, &quot;address_pkey&quot;, &quot;fk_address_cit... ## $ constraint_type &lt;chr&gt; &quot;PRIMARY KEY&quot;, &quot;PRIMARY KEY&quot;, &quot;FOREIGN KEY&quot;, ... ## $ column_name &lt;chr&gt; &quot;actor_id&quot;, &quot;address_id&quot;, &quot;city_id&quot;, &quot;categor... ## $ ordinal_position &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ... kable(keys) table_name table_type constraint_name constraint_type column_name ordinal_position actor BASE TABLE actor_pkey PRIMARY KEY actor_id 1 address BASE TABLE address_pkey PRIMARY KEY address_id 1 address BASE TABLE fk_address_city FOREIGN KEY city_id 1 category BASE TABLE category_pkey PRIMARY KEY category_id 1 city BASE TABLE city_pkey PRIMARY KEY city_id 1 city BASE TABLE fk_city FOREIGN KEY country_id 1 country BASE TABLE country_pkey PRIMARY KEY country_id 1 customer BASE TABLE customer_address_id_fkey FOREIGN KEY address_id 1 customer BASE TABLE customer_pkey PRIMARY KEY customer_id 1 film BASE TABLE film_language_id_fkey FOREIGN KEY language_id 1 film BASE TABLE film_pkey PRIMARY KEY film_id 1 film_actor BASE TABLE film_actor_actor_id_fkey FOREIGN KEY actor_id 1 film_actor BASE TABLE film_actor_film_id_fkey FOREIGN KEY film_id 1 film_actor BASE TABLE film_actor_pkey PRIMARY KEY actor_id 1 film_actor BASE TABLE film_actor_pkey PRIMARY KEY film_id 2 film_category BASE TABLE film_category_category_id_fkey FOREIGN KEY category_id 1 film_category BASE TABLE film_category_film_id_fkey FOREIGN KEY film_id 1 film_category BASE TABLE film_category_pkey PRIMARY KEY film_id 1 film_category BASE TABLE film_category_pkey PRIMARY KEY category_id 2 inventory BASE TABLE inventory_film_id_fkey FOREIGN KEY film_id 1 inventory BASE TABLE inventory_pkey PRIMARY KEY inventory_id 1 language BASE TABLE language_pkey PRIMARY KEY language_id 1 payment BASE TABLE payment_customer_id_fkey FOREIGN KEY customer_id 1 payment BASE TABLE payment_pkey PRIMARY KEY payment_id 1 payment BASE TABLE payment_rental_id_fkey FOREIGN KEY rental_id 1 payment BASE TABLE payment_staff_id_fkey FOREIGN KEY staff_id 1 rental BASE TABLE rental_customer_id_fkey FOREIGN KEY customer_id 1 rental BASE TABLE rental_inventory_id_fkey FOREIGN KEY inventory_id 1 rental BASE TABLE rental_pkey PRIMARY KEY rental_id 1 rental BASE TABLE rental_staff_id_key FOREIGN KEY staff_id 1 staff BASE TABLE staff_address_id_fkey FOREIGN KEY address_id 1 staff BASE TABLE staff_pkey PRIMARY KEY staff_id 1 store BASE TABLE store_address_id_fkey FOREIGN KEY address_id 1 store BASE TABLE store_manager_staff_id_fkey FOREIGN KEY manager_staff_id 1 store BASE TABLE store_pkey PRIMARY KEY store_id 1 What do we learn from the following query? How is it useful? rs &lt;- dbGetQuery( con, &quot;SELECT r.*, pg_catalog.pg_get_constraintdef(r.oid, true) as condef FROM pg_catalog.pg_constraint r WHERE 1=1 --r.conrelid = &#39;16485&#39; AND r.contype = &#39;f&#39; ORDER BY 1; &quot; ) head(rs) ## conname connamespace contype condeferrable ## 1 cardinal_number_domain_check 12703 c FALSE ## 2 yes_or_no_check 12703 c FALSE ## 3 year_check 2200 c FALSE ## 4 actor_pkey 2200 p FALSE ## 5 address_pkey 2200 p FALSE ## 6 category_pkey 2200 p FALSE ## condeferred convalidated conrelid contypid conindid confrelid ## 1 FALSE TRUE 0 12716 0 0 ## 2 FALSE TRUE 0 12724 0 0 ## 3 FALSE TRUE 0 16397 0 0 ## 4 FALSE TRUE 16420 0 16555 0 ## 5 FALSE TRUE 16461 0 16557 0 ## 6 FALSE TRUE 16427 0 16559 0 ## confupdtype confdeltype confmatchtype conislocal coninhcount ## 1 TRUE 0 ## 2 TRUE 0 ## 3 TRUE 0 ## 4 TRUE 0 ## 5 TRUE 0 ## 6 TRUE 0 ## connoinherit conkey confkey conpfeqop conppeqop conffeqop conexclop ## 1 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## conbin ## 1 {OPEXPR :opno 525 :opfuncid 150 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 195} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 204 :constvalue 4 [ 0 0 0 0 0 0 0 0 ]}) :location 201} ## 2 {SCALARARRAYOPEXPR :opno 98 :opfuncid 67 :useOr true :inputcollid 100 :args ({RELABELTYPE :arg {COERCETODOMAINVALUE :typeId 1043 :typeMod 7 :collation 100 :location 121} :resulttype 25 :resulttypmod -1 :resultcollid 100 :relabelformat 2 :location -1} {ARRAYCOERCEEXPR :arg {ARRAY :array_typeid 1015 :array_collid 100 :element_typeid 1043 :elements ({CONST :consttype 1043 :consttypmod -1 :constcollid 100 :constlen -1 :constbyval false :constisnull false :location 131 :constvalue 7 [ 28 0 0 0 89 69 83 ]} {CONST :consttype 1043 :consttypmod -1 :constcollid 100 :constlen -1 :constbyval false :constisnull false :location 138 :constvalue 6 [ 24 0 0 0 78 79 ]}) :multidims false :location -1} :elemfuncid 0 :resulttype 1009 :resulttypmod -1 :resultcollid 100 :isExplicit false :coerceformat 2 :location -1}) :location 127} ## 3 {BOOLEXPR :boolop and :args ({OPEXPR :opno 525 :opfuncid 150 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 62} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 71 :constvalue 4 [ 109 7 0 0 0 0 0 0 ]}) :location 68} {OPEXPR :opno 523 :opfuncid 149 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 82} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 91 :constvalue 4 [ 107 8 0 0 0 0 0 0 ]}) :location 88}) :location 77} ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## consrc ## 1 (VALUE &gt;= 0) ## 2 ((VALUE)::text = ANY ((ARRAY[&#39;YES&#39;::character varying, &#39;NO&#39;::character varying])::text[])) ## 3 ((VALUE &gt;= 1901) AND (VALUE &lt;= 2155)) ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## condef ## 1 CHECK (VALUE &gt;= 0) ## 2 CHECK (VALUE::text = ANY (ARRAY[&#39;YES&#39;::character varying, &#39;NO&#39;::character varying]::text[])) ## 3 CHECK (VALUE &gt;= 1901 AND VALUE &lt;= 2155) ## 4 PRIMARY KEY (actor_id) ## 5 PRIMARY KEY (address_id) ## 6 PRIMARY KEY (category_id) 9.6 Creating your own data dictionary If you are going to work with a database for an extended period it can be useful to create your own data dictionary. Here is an illustration of the idea some_tables &lt;- c(&quot;rental&quot;, &quot;city&quot;, &quot;store&quot;) all_meta &lt;- map_df(some_tables, sp_get_dbms_data_dictionary, con = con) all_meta ## # A tibble: 15 x 11 ## table_name var_name var_type num_rows num_blank num_unique min q_25 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 rental rental_… integer 16044 0 16044 1 4013 ## 2 rental rental_… double 16044 0 15815 2005… 2005… ## 3 rental invento… integer 16044 0 4580 1 1154 ## 4 rental custome… integer 16044 0 599 1 148 ## 5 rental return_… double 16044 183 15836 2005… 2005… ## 6 rental staff_id integer 16044 0 2 1 1 ## 7 rental last_up… double 16044 0 3 2006… 2006… ## 8 city city_id integer 600 0 600 1 150 ## 9 city city charact… 600 0 599 A Co… Dzer… ## 10 city country… integer 600 0 109 1 28 ## 11 city last_up… double 600 0 1 2006… 2006… ## 12 store store_id integer 2 0 2 1 1 ## 13 store manager… integer 2 0 2 1 1 ## 14 store address… integer 2 0 2 1 1 ## 15 store last_up… double 2 0 1 2006… 2006… ## # ... with 3 more variables: q_50 &lt;chr&gt;, q_75 &lt;chr&gt;, max &lt;chr&gt; glimpse(all_meta) ## Observations: 15 ## Variables: 11 ## $ table_name &lt;chr&gt; &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;... ## $ var_name &lt;chr&gt; &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;custom... ## $ var_type &lt;chr&gt; &quot;integer&quot;, &quot;double&quot;, &quot;integer&quot;, &quot;integer&quot;, &quot;double&quot;... ## $ num_rows &lt;int&gt; 16044, 16044, 16044, 16044, 16044, 16044, 16044, 60... ## $ num_blank &lt;int&gt; 0, 0, 0, 0, 183, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ## $ num_unique &lt;int&gt; 16044, 15815, 4580, 599, 15836, 2, 3, 600, 599, 109... ## $ min &lt;chr&gt; &quot;1&quot;, &quot;2005-05-24 22:53:30&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2005-05-25 2... ## $ q_25 &lt;chr&gt; &quot;4013&quot;, &quot;2005-07-07 00:58:00&quot;, &quot;1154&quot;, &quot;148&quot;, &quot;2005... ## $ q_50 &lt;chr&gt; &quot;8025&quot;, &quot;2005-07-28 16:03:27&quot;, &quot;2291&quot;, &quot;296&quot;, &quot;2005... ## $ q_75 &lt;chr&gt; &quot;12037&quot;, &quot;2005-08-17 21:13:35&quot;, &quot;3433&quot;, &quot;446&quot;, &quot;200... ## $ max &lt;chr&gt; &quot;16049&quot;, &quot;2006-02-14 15:16:03&quot;, &quot;4581&quot;, &quot;599&quot;, &quot;200... kable(head(all_meta)) table_name var_name var_type num_rows num_blank num_unique min q_25 q_50 q_75 max rental rental_id integer 16044 0 16044 1 4013 8025 12037 16049 rental rental_date double 16044 0 15815 2005-05-24 22:53:30 2005-07-07 00:58:00 2005-07-28 16:03:27 2005-08-17 21:13:35 2006-02-14 15:16:03 rental inventory_id integer 16044 0 4580 1 1154 2291 3433 4581 rental customer_id integer 16044 0 599 1 148 296 446 599 rental return_date double 16044 183 15836 2005-05-25 23:55:21 2005-07-10 15:48:58 2005-08-01 19:31:15 2005-08-20 23:32:29 2005-09-02 02:35:22 rental staff_id integer 16044 0 2 1 1 1 2 2 ## Save your work! The work you do to understand the structure and contents of a database can be useful for others (including future-you). So at the end of a session, you might look at all the data frames you want to save. Consider saving them in a form where you can add notes at the appropriate level (as in a Google Doc representing table or columns that you annotate over time). ls() ## [1] &quot;all_meta&quot; &quot;columns_info_schema_info&quot; ## [3] &quot;columns_info_schema_table&quot; &quot;con&quot; ## [5] &quot;constraint_column_usage&quot; &quot;cranex&quot; ## [7] &quot;key_column_usage&quot; &quot;keys&quot; ## [9] &quot;public_tables&quot; &quot;referential_constraints&quot; ## [11] &quot;rental&quot; &quot;rs&quot; ## [13] &quot;some_tables&quot; &quot;table_constraints&quot; ## [15] &quot;table_info&quot; &quot;table_info_schema_table&quot; ## [17] &quot;table_list&quot; &quot;tables&quot; "],
["drilling-into-your-db-environment-22.html", "Chapter 10 Drilling into Your DB Environment (22) 10.1 Which database? 10.2 How many databases reside in the Docker Container? 10.3 Which Schema? 10.4 Exercises", " Chapter 10 Drilling into Your DB Environment (22) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 10.1 Which database? Your DBA will create your user accounts and priviledges for the database(s) that you can access. One of the challenges when working with a database(s) is finding where your data actually resides. Your best resources will be one or more subject matter experts, SME, and your DBA. Your data may actually reside in multiple databases, e.g., a detail and summary databases. In our tutorial, we focus on the one database, dvdrental. Database names usually reflect something about the data that they contain. Your laptop is a server for the Docker Postgres databases. A database is a collection of files that Postgres manages in the background. 10.2 How many databases reside in the Docker Container? rs &lt;- DBI::dbGetQuery( con, &quot;SELECT &#39;DB Names in Docker&#39; showing ,datname DB FROM pg_database WHERE datistemplate = false; &quot; ) kable(rs) showing db DB Names in Docker postgres DB Names in Docker dvdrental Which databases are available? Modify the connection call to connect to the `postgres` database. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;your code goes here&quot;, seconds_to_test = 10) con ## [1] &quot;There is no connection&quot; if (con != &#39;There is no connection&#39;) dbDisconnect(con) #Answer: con &lt;PqConnection&gt; postgres@localhost:5432 # Reconnect to dvdrental con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 Note that the two Sys.getenv function calls work in this tutorial because both the user and password are available in both databases. This is a common practice in organinzations that have implemented single sign on across their organization. Gotcha: If one has data in multiple databases or multiple environments, Development, Integration, and Prodution, it is very easy to connect to the wrong database in the wrong environment. Always double check your connection information when logging in and before performing any inserts, updates, or deletes against the database. The following code block should be used to reduce propagating the above gotcha. Current_database(), CURRENT_DATE or CURRENT_TIMESTAMP, and ‘result set’ are the most useful and last three not so much. Instead of the host IP address having the actual hostname would be a nice addition. rs1 &lt;- DBI::dbGetQuery( con, &quot;SELECT current_database() DB ,CURRENT_DATE ,CURRENT_TIMESTAMP ,&#39;result set description&#39; showing ,session_user ,inet_server_addr() host ,inet_server_port() port &quot; ) kable(display_rows) x 5 Since we will only be working in the dvdrental database in this tutorial and reduce the number of output columns shown, only the ‘result set description’ will be used. 10.3 Which Schema? In the code block below, we look at the information_schema.table which contains information about all the schemas and table/views within our dvdrental database. Databases can have one or more schemas, containers that hold tables or views. Schemas partition the database into big logical blocks of related data. Schema names usually reflect an application or logically related datasets. Occasionally a DBA will set up a new schema and use a users name. What schemas are in the dvdrental database? How many entries are in each schema? ## Database Schemas # rs1 &lt;- DBI::dbGetQuery( con, &quot;SELECT &#39;DB Schemas&#39; showing,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot; ) kable(rs1) showing db table_schema tbl_vws DB Schemas dvdrental pg_catalog 121 DB Schemas dvdrental public 22 DB Schemas dvdrental information_schema 67 We see that there are three schemas. The pg_catalog is the standard PostgreSQL meta data and core schema. Postgres uses this schema to manage the internal workings of the database. DBA’s are the primary users of pg_catalog. We used the pg_catalog schema to answer the question ‘How many databases reside in the Docker Container?’, but normally the data analyst is not interested in analyzing database data. The information_schema contains ANSI standardized views used across the different SQL vendors, (Oracle, Sysbase, MS SQL Server, IBM DB2, etc). The information_schema contains a plethora of metadata that will help you locate your data tables, understand the relationships between the tables, and write efficient SQL queries. 10.4 Exercises # # Add an order by clause to order the output by the table catalog. rs1 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;1. ORDER BY table_catalog&#39; showing ,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot; ) kable(rs1) showing db table_schema tbl_vws 1. ORDER BY table_catalog dvdrental pg_catalog 121 1. ORDER BY table_catalog dvdrental public 22 1. ORDER BY table_catalog dvdrental information_schema 67 # Add an order by clause to order the output by tbl_vws in descending order. rs2 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;2. ORDER BY tbl_vws desc&#39; showing ,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot; ) kable(rs2) showing db table_schema tbl_vws 2. ORDER BY tbl_vws desc dvdrental pg_catalog 121 2. ORDER BY tbl_vws desc dvdrental public 22 2. ORDER BY tbl_vws desc dvdrental information_schema 67 # Complete the SQL statement to show everything about all the tables. rs3 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;3. all information_schema tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t &quot; ) kable(head (rs3,display_rows)) showing ?column? 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here # Use the results from above to pull interesting columns from just the information_schema rs4 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;4. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot; ) head(rs4,display_rows) ## showing ?column? ## 1 4. information_schema.tables your code goes here ## 2 4. information_schema.tables your code goes here ## 3 4. information_schema.tables your code goes here ## 4 4. information_schema.tables your code goes here ## 5 4. information_schema.tables your code goes here # Modify the SQL below with your interesting column names. # Update the where clause to return only rows from the information schema and begin with &#39;tab&#39; rs5 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;5. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot; ) kable(head(rs5,display_rows)) showing ?column? 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here # Modify the SQL below with your interesting column names. # Update the where clause to return only rows from the information schema and begin with &#39;col&#39; rs6 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;6. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot; ) kable(head(rs6,display_rows)) showing ?column? 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here In the next exercise we combine both the table and column output from the previous exercises. Review the following code block. The last two lines of the WHERE clause are swithced. Will the result set be the same or different? Execute the code block and review the two datasets. rs7 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;7. information_schema.tables&#39; showing ,table_catalog||&#39;.&#39;||table_schema db_info, table_name, table_type FROM information_schema.tables t where table_schema = &#39;information_schema&#39; and table_name like &#39;table%&#39; OR table_name like &#39;%col%&#39; and table_type = &#39;VIEW&#39; &quot; ) kable(head(rs7,display_rows)) showing db_info table_name table_type 7. information_schema.tables dvdrental.information_schema collations VIEW 7. information_schema.tables dvdrental.information_schema collation_character_set_applicability VIEW 7. information_schema.tables dvdrental.information_schema column_domain_usage VIEW 7. information_schema.tables dvdrental.information_schema column_privileges VIEW 7. information_schema.tables dvdrental.information_schema column_udt_usage VIEW rs8 &lt;- DBI::dbGetQuery(con,&quot;SELECT &#39;8. information_schema.tables&#39; showing ,table_catalog||&#39;.&#39;||table_schema db_info, table_name, table_type FROM information_schema.tables t where table_schema = &#39;information_schema&#39; and table_type = &#39;VIEW&#39; and table_name like &#39;table%&#39; OR table_name like &#39;%col%&#39; &quot; ) kable(head(rs8,display_rows)) showing db_info table_name table_type 8. information_schema.tables dvdrental.information_schema column_options VIEW 8. information_schema.tables dvdrental.information_schema _pg_foreign_table_columns VIEW 8. information_schema.tables dvdrental.information_schema view_column_usage VIEW 8. information_schema.tables dvdrental.information_schema triggered_update_columns VIEW 8. information_schema.tables dvdrental.information_schema tables VIEW Operator/Element Associativity Description . left table/column name separator :: left PostgreSQL-style typecast [ ] left array element selection - right unary minus ^ left exponentiation * / % left multiplication, division, modulo + - left addition, subtraction IS IS TRUE, IS FALSE, IS UNKNOWN, IS NULL ISNULL test for null NOTNULL test for not null (any other) left all other native and user-defined operators IN set membership BETWEEN range containment OVERLAPS time interval overlap LIKE ILIKE SIMILAR string pattern matching &lt; &gt; less than, greater than = right equality, assignment NOT right logical negation AND left logical conjunction OR left logical disjunction rs1 &lt;- DBI::dbGetQuery(con,&quot;SELECT t.table_catalog DB ,t.table_schema ,t.table_name,t.table_type FROM information_schema.tables t&quot;) rs2 &lt;- DBI::dbGetQuery(con,&quot;SELECT t.table_catalog DB ,t.table_schema ,t.table_type,COUNT(*) tbls FROM information_schema.tables t group by t.table_catalog ,t.table_schema ,t.table_type &quot;) rs3 &lt;- DBI::dbGetQuery(con,&quot;SELECT distinct t.table_catalog DB ,t.table_schema ,t.table_type tbls FROM information_schema.tables t &quot;) #kable(head(rs1 %&gt;% arrange (table_name))) # View(rs1) # View(rs2) # View(rs3) kable(head(rs1)) db table_schema table_name table_type dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public staff BASE TABLE kable(head(rs2)) db table_schema table_type tbls dvdrental information_schema BASE TABLE 7 dvdrental information_schema VIEW 60 dvdrental pg_catalog BASE TABLE 62 dvdrental public BASE TABLE 15 dvdrental public VIEW 7 dvdrental pg_catalog VIEW 59 kable(head(rs3)) db table_schema tbls dvdrental information_schema BASE TABLE dvdrental information_schema VIEW dvdrental pg_catalog BASE TABLE dvdrental public BASE TABLE dvdrental public VIEW dvdrental pg_catalog VIEW www.dataquest.io/blog/postgres-internals Comment on the practice of putting a comma at the beginning of a line in SQL code. ## Explain a `dplyr::join tbl_pk_fk_df &lt;- DBI::dbGetQuery(con, &quot; SELECT --t.table_catalog,t.table_schema, c.table_name ,kcu.column_name ,c.constraint_name ,c.constraint_type ,coalesce(c2.table_name, &#39;&#39;) ref_table ,coalesce(kcu2.column_name, &#39;&#39;) ref_table_col FROM information_schema.tables t LEFT JOIN information_schema.table_constraints c ON t.table_catalog = c.table_catalog AND t.table_schema = c.table_schema AND t.table_name = c.table_name LEFT JOIN information_schema.key_column_usage kcu ON c.constraint_schema = kcu.constraint_schema AND c.constraint_name = kcu.constraint_name LEFT JOIN information_schema.referential_constraints rc ON c.constraint_schema = rc.constraint_schema AND c.constraint_name = rc.constraint_name LEFT JOIN information_schema.table_constraints c2 ON rc.unique_constraint_schema = c2.constraint_schema AND rc.unique_constraint_name = c2.constraint_name LEFT JOIN information_schema.key_column_usage kcu2 ON c2.constraint_schema = kcu2.constraint_schema AND c2.constraint_name = kcu2.constraint_name AND kcu.ordinal_position = kcu2.ordinal_position WHERE c.constraint_type IN (&#39;PRIMARY KEY&#39;, &#39;FOREIGN KEY&#39;) AND c.table_catalog = &#39;dvdrental&#39; AND c.table_schema = &#39;public&#39; ORDER BY c.table_name; &quot;) # View(tbl_pk_fk_df) tables_df &lt;- tbl_pk_fk_df %&gt;% distinct(table_name) # View(tables_df) library(DiagrammeR) table_nodes_ndf &lt;- create_node_df( n &lt;- nrow(tables_df) ,type &lt;- &#39;table&#39; ,label &lt;- tables_df$table_name ,shape = &quot;rectangle&quot; ,width = 1 ,height = .5 ,fontsize = 18 ) tbl_pk_fk_ids_df &lt;- inner_join(tbl_pk_fk_df,table_nodes_ndf ,by = c(&#39;table_name&#39; = &#39;label&#39;) ,suffix(c(&#39;st&#39;,&#39;s&#39;)) ) %&gt;% rename(&#39;src_tbl_id&#39; = id) %&gt;% left_join(table_nodes_ndf ,by = c(&#39;ref_table&#39; = &#39;label&#39;) ,suffix(c(&#39;st&#39;,&#39;t&#39;)) ) %&gt;% rename(&#39;fk_tbl_id&#39; = id) tbl_fk_df &lt;- tbl_pk_fk_ids_df %&gt;% filter(constraint_type == &#39;FOREIGN KEY&#39;) tbl_pk_df &lt;- tbl_pk_fk_ids_df %&gt;% filter(constraint_type == &#39;PRIMARY KEY&#39;) # View(tbl_pk_fk_ids_df) # View(tbl_fk_df) # View(tbl_pk_df) kable(head(tbl_fk_df)) table_name column_name constraint_name constraint_type ref_table ref_table_col src_tbl_id type.x shape.x width.x height.x fontsize.x fk_tbl_id type.y shape.y width.y height.y fontsize.y address city_id fk_address_city FOREIGN KEY city city_id 2 table rectangle 1 0.5 18 4 table rectangle 1 0.5 18 city country_id fk_city FOREIGN KEY country country_id 4 table rectangle 1 0.5 18 5 table rectangle 1 0.5 18 customer address_id customer_address_id_fkey FOREIGN KEY address address_id 6 table rectangle 1 0.5 18 2 table rectangle 1 0.5 18 film language_id film_language_id_fkey FOREIGN KEY language language_id 7 table rectangle 1 0.5 18 11 table rectangle 1 0.5 18 film_actor actor_id film_actor_actor_id_fkey FOREIGN KEY actor actor_id 8 table rectangle 1 0.5 18 1 table rectangle 1 0.5 18 film_actor film_id film_actor_film_id_fkey FOREIGN KEY film film_id 8 table rectangle 1 0.5 18 7 table rectangle 1 0.5 18 kable(head(tbl_pk_df)) table_name column_name constraint_name constraint_type ref_table ref_table_col src_tbl_id type.x shape.x width.x height.x fontsize.x fk_tbl_id type.y shape.y width.y height.y fontsize.y actor actor_id actor_pkey PRIMARY KEY 1 table rectangle 1 0.5 18 NA NA NA NA NA NA address address_id address_pkey PRIMARY KEY 2 table rectangle 1 0.5 18 NA NA NA NA NA NA category category_id category_pkey PRIMARY KEY 3 table rectangle 1 0.5 18 NA NA NA NA NA NA city city_id city_pkey PRIMARY KEY 4 table rectangle 1 0.5 18 NA NA NA NA NA NA country country_id country_pkey PRIMARY KEY 5 table rectangle 1 0.5 18 NA NA NA NA NA NA customer customer_id customer_pkey PRIMARY KEY 6 table rectangle 1 0.5 18 NA NA NA NA NA NA # Create an edge data frame, edf fk_edf &lt;- create_edge_df( from = tbl_fk_df$src_tbl_id, to = tbl_fk_df$fk_tbl_id, rel = &quot;fk&quot;, label = tbl_fk_df$constraint_name, fontsize = 15 ) # View(fk_edf) graph &lt;- create_graph( nodes_df = table_nodes_ndf, edges_df = fk_edf, graph_name = &#39;Simple FK Graph&#39; ) # View the graph render_graph(graph) dbDisconnect(con) # system2(&#39;docker&#39;,&#39;stop sql-pet&#39;) "],
["explain-queries-71.html", "Chapter 11 Explain queries (71) 11.1 Performance considerations 11.2 Clean up", " Chapter 11 Explain queries (71) examining dplyr queries (dplyr::show_query on the R side v EXPLAIN on the PostgreSQL side) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) now connect to the database with R con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) 11.1 Performance considerations ## Explain a `dplyr::join` ## Explain the quivalent SQL join rs1 &lt;- DBI::dbGetQuery(con ,&quot;SELECT c.* FROM pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = &#39;public&#39; AND c.relname = &#39;cust_movies&#39; AND c.relkind = &#39;r&#39; ; &quot; ) head(rs1) ## [1] relname relnamespace reltype ## [4] reloftype relowner relam ## [7] relfilenode reltablespace relpages ## [10] reltuples relallvisible reltoastrelid ## [13] relhasindex relisshared relpersistence ## [16] relkind relnatts relchecks ## [19] relhasoids relhaspkey relhasrules ## [22] relhastriggers relhassubclass relrowsecurity ## [25] relforcerowsecurity relispopulated relreplident ## [28] relispartition relfrozenxid relminmxid ## [31] relacl reloptions relpartbound ## &lt;0 rows&gt; (or 0-length row.names) This came from 14-sql_pet-examples-part-b.Rmd rs1 &lt;- DBI::dbGetQuery(con, &quot;explain select r.* from rental r ;&quot; ) head(rs1) ## QUERY PLAN ## 1 Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=36) rs2 &lt;- DBI::dbGetQuery(con, &quot;explain select count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id where p.rental_id is null ;&quot;) head(rs2) ## QUERY PLAN ## 1 Aggregate (cost=896.49..896.50 rows=1 width=8) ## 2 -&gt; Hash Anti Join (cost=436.41..892.86 rows=1452 width=0) ## 3 Hash Cond: (r.rental_id = p.rental_id) ## 4 -&gt; Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=4) ## 5 -&gt; Hash (cost=253.96..253.96 rows=14596 width=4) ## 6 -&gt; Seq Scan on payment p (cost=0.00..253.96 rows=14596 width=4) rs3 &lt;- DBI::dbGetQuery(con, &quot;explain select sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where p.rental_id is null ;&quot;) head(rs3) ## QUERY PLAN ## 1 Aggregate (cost=1101.11..1101.12 rows=1 width=40) ## 2 -&gt; Hash Join (cost=987.51..1093.84 rows=1452 width=6) ## 3 Hash Cond: (i.film_id = f.film_id) ## 4 -&gt; Hash Join (cost=911.01..1013.52 rows=1452 width=2) ## 5 Hash Cond: (i.inventory_id = r.inventory_id) ## 6 -&gt; Seq Scan on inventory i (cost=0.00..70.81 rows=4581 width=6) rs4 &lt;- DBI::dbGetQuery(con, &quot;explain select c.customer_id,c.first_name,c.last_name,sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join customer c on r.customer_id = c.customer_id where p.rental_id is null group by c.customer_id,c.first_name,c.last_name order by open_amt desc ;&quot; ) head(rs4) ## QUERY PLAN ## 1 Sort (cost=1166.16..1167.66 rows=599 width=57) ## 2 Sort Key: (sum(f.rental_rate)) DESC ## 3 -&gt; HashAggregate (cost=1131.04..1138.53 rows=599 width=57) ## 4 Group Key: c.customer_id ## 5 -&gt; Hash Join (cost=1009.99..1120.15 rows=1452 width=23) ## 6 Hash Cond: (r.customer_id = c.customer_id) 11.2 Clean up # dbRemoveTable(con, &quot;cars&quot;) # dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; "],
["sql-queries-behind-the-scenes-72.html", "Chapter 12 SQL queries behind the scenes (72) 12.1 SQL Execution Steps 12.2 Passing values to SQL statements 12.3 Pass multiple sets of values with dbBind(): 12.4 Clean up", " Chapter 12 SQL queries behind the scenes (72) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) now connect to the database with R con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) 12.1 SQL Execution Steps Parse the incoming SQL query Compile the SQL query Plan/optimize the data acquisition path Execute the optimized query / acquire and return data dbWriteTable(con, &quot;mtcars&quot;, mtcars, overwrite = TRUE) rs &lt;- dbSendQuery(con, &quot;SELECT * FROM mtcars WHERE cyl = 4&quot;) dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 2 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 3 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 7 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## 8 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 9 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 11 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 dbClearResult(rs) 12.2 Passing values to SQL statements #Pass one set of values with the param argument: rs &lt;- dbSendQuery(con,&quot;SELECT * FROM mtcars WHERE cyl = 4&quot;) dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 2 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 3 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 7 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## 8 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 9 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 11 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 dbClearResult(rs) 12.3 Pass multiple sets of values with dbBind(): rs &lt;- dbSendQuery(con, &quot;SELECT * FROM mtcars WHERE cyl = $1&quot;) dbBind(rs, list(6L)) # cyl = 6 dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## 3 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## 4 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## 5 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## 6 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## 7 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 dbBind(rs, list(8L)) # cyl = 8 dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## 2 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## 3 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## 4 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## 5 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## 6 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## 7 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## 8 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## 9 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## 10 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## 11 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## 12 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## 13 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## 14 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 dbClearResult(rs) 12.4 Clean up # dbRemoveTable(con, &quot;cars&quot;) dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; "],
["writing-to-the-dbms-73.html", "Chapter 13 Writing to the DBMS (73) 13.1 create a new table 13.2 Modify an existing table 13.3 Clean up", " Chapter 13 Writing to the DBMS (73) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) now connect to the database with R con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) 13.1 create a new table This is an example from the DBI help file dbWriteTable(con, &quot;cars&quot;, head(cars, 3)) # &quot;cars&quot; is a built-in dataset, not to be confused with mtcars dbReadTable(con, &quot;cars&quot;) # there are 3 rows ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 13.2 Modify an existing table dbExecute( con, &quot;INSERT INTO cars (speed, dist) VALUES (1, 1), (2, 2), (3, 3)&quot; ) ## [1] 3 dbReadTable(con, &quot;cars&quot;) # there are now 6 rows ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 1 1 ## 5 2 2 ## 6 3 3 # Pass values using the param argument: dbExecute( con, &quot;INSERT INTO cars (speed, dist) VALUES ($1, $2)&quot;, param = list(4:7, 5:8) ) ## [1] 4 dbReadTable(con, &quot;cars&quot;) # there are now 10 rows ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 1 1 ## 5 2 2 ## 6 3 3 ## 7 4 5 ## 8 5 6 ## 9 6 7 ## 10 7 8 13.3 Clean up dbRemoveTable(con, &quot;cars&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) ## [1] &quot;sql-pet&quot; "],
["other-resources-89.html", "Chapter 14 Other resources (89) 14.1 Editing this book 14.2 Docker alternatives 14.3 Docker and R 14.4 Documentation for Docker and Postgres 14.5 More Resources", " Chapter 14 Other resources (89) 14.1 Editing this book Here are instructions for editing this tutorial 14.2 Docker alternatives Choosing between Docker and Vagrant 14.3 Docker and R Noam Ross’ talk on Docker for the UseR and his Slides give a lot of context and tips. Good Docker tutorials An introductory Docker tutorial A Docker curriculum Scott Came’s materials about Docker and R on his website and at the 2018 UseR Conference focus on R inside Docker. It’s worth studying the ROpensci Docker tutorial 14.4 Documentation for Docker and Postgres The Postgres image documentation Dockerize PostgreSQL Postgres &amp; Docker documentation Usage examples of Postgres with Docker 14.5 More Resources David Severski describes some key elements of connecting to databases with R for MacOS users This tutorial picks up ideas and tips from Ed Borasky’s Data Science pet containers, which creates a framework based on that Hack Oregon example and explains why this repo is named pet-sql. "],
["references.html", "References", " References "],
["mapping-your-local-environment-92.html", "Chapter 15 Mapping your local environment (92) 15.1 Environment Tools Used in this Chapter 15.2 Communicating with Docker Applications", " Chapter 15 Mapping your local environment (92) 15.1 Environment Tools Used in this Chapter Note that tidyverse, DBI, RPostgres, glue, and knitr are loaded. Also, we’ve sourced the [db-login-batch-code.R]('r-database-docker/book-src/db-login-batch-code.R') file which is used to log in to PostgreSQL. library(rstudioapi) The following code block defines Tool and versions for the graph that follows. The information order corresponds to the order shown in the graph. library(DiagrammeR) ## OS information os_lbl &lt;- .Platform$OS.type os_ver &lt;- 0 if (os_lbl == &#39;windows&#39;) { os_ver &lt;- system2(&#39;cmd&#39;,stdout = TRUE) %&gt;% grep(x = .,pattern = &#39;Microsoft Windows \\\\[&#39;,value = TRUE) %&gt;% gsub(x = .,pattern = &quot;^Microsoft.+Version |\\\\]&quot;, replace = &#39;&#39;) } if (os_lbl == &#39;unix&#39; || os_lbl == &#39;Linux&#39; || os_lbl == &#39;Mac&#39;) { os_ver &lt;- system2(&#39;uname&#39;, &#39;-r&#39;, stdout = TRUE) } ## Command line interface into Docker Apps ## CLI/system2 cli &lt;- array(dim = 3) cli[1] &lt;- &quot;docker [OPTIONS] COMMAND ARGUMENTS\\n\\nsystem2(docker,[OPTIONS,]\\n, COMMAND,ARGUMENTS)&quot; cli[2] &lt;- &#39;docker exec -it sql-pet bash\\n\\nsystem2(docker,exec -it sql-pet bash)&#39; cli[3] &lt;- &#39;docker exec -ti sql-pet psql -a \\n-p 5432 -d dvdrental -U postgres\\n\\nsystem2(docker,exec -ti sql-pet psql -a \\n-p 5432 -d dvdrental -U postgres)&#39; # R Information r_lbl &lt;- names(R.Version())[1:7] r_ver &lt;- R.Version()[1:7] # RStudio Information rstudio_lbl &lt;- c(&#39;RStudio version&#39;,&#39;Current program mode&#39;) rstudio_ver &lt;- c(as.character(rstudioapi::versionInfo()$version),rstudioapi::versionInfo()$mode) # Docker Information docker_lbl &lt;- c(&#39;client version&#39;,&#39;server version&#39;) docker_ver &lt;- system2(&quot;docker&quot;, &quot;version&quot;, stdout = TRUE) %&gt;% grep(x = ., pattern = &#39;Version&#39;,value = TRUE) %&gt;% gsub(x = ., pattern = &#39; +Version: +&#39;, replacement = &#39;&#39;) # Linux Information linux_lbl &lt;- &#39;Linux Version&#39; linux_ver &lt;- system2(&#39;docker&#39;, &#39;exec -i sql-pet /bin/uname -r&#39;, stdout = TRUE) # Postgres Information con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 10) postgres_ver &lt;- dbGetQuery(con,&quot;select version()&quot;) %&gt;% gsub(x = ., pattern = &#39;\\\\(.*$&#39;, replacement = &#39;&#39;) The following code block uses the data generated from the previous code block as input to the subgraphs, the ones outlined in red. The application nodes are the parents of the subgraphs and are not outlined in red. The Environment application node represents the machine you are running the tutorial on and hosts the sub-applications. Note that the ‘@@’ variables are populated at the end of the Environment definition following the ## @@1 - @@5 source data comment. grViz(&quot; digraph Envgraph { # graph, node, and edge definitions graph [compound = true, nodesep = .5, ranksep = .25, color = red] node [fontname = Helvetica, fontcolor = darkslategray, shape = rectangle, fixedsize = true, width = 1, color = darkslategray] edge [color = grey, arrowhead = none, arrowtail = none] # subgraph for Environment information subgraph cluster1 { node [fixedsize = true, width = 3] &#39;@@1-1&#39; } # subgraph for R information subgraph cluster2 { node [fixedsize = true, width = 3] &#39;@@2-1&#39; -&gt; &#39;@@2-2&#39; -&gt; &#39;@@2-3&#39; -&gt; &#39;@@2-4&#39; &#39;@@2-4&#39; -&gt; &#39;@@2-5&#39; -&gt; &#39;@@2-6&#39; -&gt; &#39;@@2-7&#39; } # subgraph for RStudio information subgraph cluster3 { node [fixedsize = true, width = 3] &#39;@@3-1&#39; -&gt; &#39;@@3-2&#39; } # subgraph for Docker information subgraph cluster4 { node [fixedsize = true, width = 3] &#39;@@4-1&#39; -&gt; &#39;@@4-2&#39; } # subgraph for Docker-Linux information subgraph cluster5 { node [fixedsize = true, width = 3] &#39;@@5-1&#39; } # subgraph for Docker-Postgres information subgraph cluster6 { node [fixedsize = true, width = 3] &#39;@@6-1&#39; } # subgraph for Docker-Postgres information subgraph cluster7 { node [fixedsize = true, height = 1.25, width = 4.0] &#39;@@7-1&#39; -&gt; &#39;@@7-2&#39; -&gt; &#39;@@7-3&#39; } CLI [label=&#39;CLI\\nRStudio system2&#39;,height = .75,width=3.0, color = &#39;blue&#39; ] Environment [label = &#39;Linux,Mac,Windows&#39;,width = 2.5] Environment -&gt; R Environment -&gt; RStudio Environment -&gt; Docker Environment -&gt; &#39;@@1&#39; [lhead = cluster1] # Environment Information R -&gt; &#39;@@2-1&#39; [lhead = cluster2] # R Information RStudio -&gt; &#39;@@3&#39; [lhead = cluster3] # RStudio Information Docker -&gt; &#39;@@4&#39; [lhead = cluster4] # Docker Information Docker -&gt; &#39;@@5&#39; [lhead = cluster5] # Docker-Linux Information Docker -&gt; &#39;@@6&#39; [lhead = cluster6] # Docker-Postgres Information &#39;@@1&#39; -&gt; CLI CLI -&gt; &#39;@@7&#39; [lhead = cluster7] # CLI &#39;@@7-2&#39; -&gt; &#39;@@5&#39; &#39;@@7-3&#39; -&gt; &#39;@@6&#39; } [1]: paste0(os_lbl, &#39;:\\\\n&#39;, os_ver) [2]: paste0(r_lbl, &#39;:\\\\n&#39;, r_ver) [3]: paste0(rstudio_lbl,&#39;:\\\\n&#39;, rstudio_ver) [4]: paste0(docker_lbl, &#39;:\\\\n&#39;, docker_ver) [5]: paste0(linux_lbl, &#39;:\\\\n&#39;, linux_ver) [6]: paste0(&#39;PostgreSQL:\\\\n&#39;, postgres_ver) [7]: cli &quot;) One sub-application not shown above is your local console/terminal/CLI application. In the tutorial, fully constructed docker commands are printed out and then executed. If for some reason the executed docker command fails, one can copy and paste it into your local terminal window to see additional error information. Failures seem more prevalent in the Windows environment. 15.2 Communicating with Docker Applications In this tutorial, the two main ways to interface with the applications in the Docker container are through the CLI or the RStudio system2 command. The blue box in the diagram above represents these two interfaces. "]
]
